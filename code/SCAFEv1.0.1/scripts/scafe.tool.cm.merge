#!/usr/bin/env perl

# This chunk of stuff was generated by App::FatPacker. To find the original
# file's code, look for the end of this BEGIN block or the string 'FATPACK'
BEGIN {
my %fatpacked;

s/^  //mg for values %fatpacked;

my $class = 'FatPacked::'.(0+\%fatpacked);
no strict 'refs';
*{"${class}::files"} = sub { keys %{$_[0]} };

if ($] < 5.008) {
  *{"${class}::INC"} = sub {
    if (my $fat = $_[0]{$_[1]}) {
      my $pos = 0;
      my $last = length $fat;
      return (sub {
        return 0 if $pos == $last;
        my $next = (1 + index $fat, "\n", $pos) || $last;
        $_ .= substr $fat, $pos, $next - $pos;
        $pos = $next;
        return 1;
      });
    }
  };
}

else {
  *{"${class}::INC"} = sub {
    if (my $fat = $_[0]{$_[1]}) {
      open my $fh, '<', \$fat
        or die "FatPacker error loading $_[1] (could be a perl installation issue?)";
      return $fh;
    }
    return;
  };
}

unshift @INC, bless \%fatpacked, $class;
  } # END OF FATPACK CODE


#====================================================================================================================================================#
#<use>
$|++; #---turn on the auto flush for the progress bar
no warnings 'utf8';
use warnings;
use strict;
use File::Path;
use File::Copy;
use File::Basename;
use File::Spec::Functions qw(rel2abs abs2rel);
use Time::HiRes qw( time );
use Getopt::Long 'HelpMessage';
use threads ('stack_size' => 64*4096);
use threads::shared;
use List::Util qw (sum shuffle min max);
use Cwd 'abs_path';
use AutoLoader qw/AUTOLOAD/;
#<\use>
#====================================================================================================================================================#

#====================================================================================================================================================#
#<doc>
=head1 SYNOPSIS

           5'-O~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~AAA-3'
                        O~~~AA      O~~         O~       O~~~~~~~AO~~~~~~~~A
                      O~~    O~~ O~~   O~~     O~O~~     O~~      O~~       
                       O~~      O~~           O~  O~~    O~~      O~~       
                         O~~    O~~          O~~   O~~   O~~~~~AA O~~~~~~A  
                            O~~ O~~         O~~~~~A O~~  O~~      O~~       
                      O~~    O~~ O~~   O~~ O~~       O~~ O~~      O~~       
                        O~~~~A     O~~~   O~~         O~~O~~      O~~~~~~~AA
       ┌─ᐅ 5'-O~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-3'
 ...===┴========================================================================================...

                      Single Cell Analysis of Five-prime End (SCAFE) Tool Suite 
                                  ---> scafe.tool.cm.merge <---
                <--- tool, common mode, merge clusters from multiple samples --->

 Description:
   This tool merges multiple cluster bed files, regardless of single cell or bulk

 Usage:
   scafe.tool.cm.merge [options] --lib_list_path --aggregated_collapse_ctss_bed_path --aggregated_unencoded_G_collapse_ctss_bed_path --outputPrefix --outDir

   --lib_list_path                                 <required> [string]  a list of libraries, in formation of 
                                                                        $libID<\t>$tssCluster_filter_log_path<\t>$tssCluster_all_bed_path
                                                                        $libID = Unique ID of the lib
                                                                        $tssCluster_filter_log_path = *.tssCluster.log.tsv from the scafe.tool.cm.filter
                                                                        $tssCluster_all_bed_path = *.tssCluster.all.bed.gz from the scafe.tool.cm.filter
   --aggregated_collapse_ctss_bed_path             <required> [string]  ctss file used for counting using for caculation of paraclu_input_summit_count and paraclu_input_cluster_count, 
                                                                        *.collapse.ctss.bed.gz from running scafe.tool.cm.aggregate on ctss of all libs in lib_list_path
   --aggregated_unencoded_G_collapse_ctss_bed_path <required> [string]  ctss file used for counting using for caculation of summit_count and cluster_count and min_nt_count
                                                                        *.unencoded_G.collapse.ctss.bed.gz from running scafe.tool.cm.aggregate on ctss of all libs in lib_list_path
   --genome                                        <required> [string]  name of genome reference, e.g. hg19.gencode_v32lift37
   --merge_dist                                    <optional> [integer] distance between tssClusters to be merged, i.e. -d option in bedtools merge [default 25]
   --min_ung_count                                 <optional> [integer] minimum number of unencoded G count in the final merged cluster [default 8]
   --min_count                                     <optional> [integer] minimum number of total count in the final merged cluster [default 10]
   --min_ung_num_pos                               <optional> [integer] minimum number of postion with non-zero unencoded G count in the final merged cluster [default 4]
   --min_num_pos                                   <optional> [integer] minimum number of postion with non-zero total count in the final merged cluster [default 5]
   --min_ung_max                                   <optional> [integer] minimum number of unencoded G count at the highest (unencoded G count) postion in the final merged cluster [default 4]
   --min_max                                       <optional> [integer] minimum number of total count at the highest (total count) postion in the final merged cluster [default 5]
   --min_ung_at_total_summit                       <optional> [integer] minimum number of unencoded G count at the highest (total count) postion in the final merged cluster [default 0]
   --summit_flank_size                             <optional> [integer] number nucleotide flanking the summit to be extracted to calculate flank_A_frac and A_stretch [default 25]
   --summit_dnStrm_size                            <optional> [integer] number nucleotide downstream the summit to be extracted to calculate dnStrm_A_frac [default 10]
   --max_summit_dnStrm_A_frac                      <optional> [integer] maximum fraction of As in downstream sequence (size specified in summit_dnStrm_size) [default 0.8]
   --max_flank_A_frac                              <optional> [integer] maximum fraction of As in flanking sequence (size specified in summit_flank_size) [default 0.75]
   --max_A_stretch_length                          <optional> [integer] maximum stretch length of As (1 mismatch allowed) in flanking sequence (size specified in summit_flank_size) [default 20]
   --force_retain_CRE_bed                          <optional> [string]  A bed file contain CREs. If specified, the final merged tssClusters from will be retained regardless of any filter values (except max_summit_dnStrm_A_frac).
                                                                        It should be noted that the tssClusters from the individual libraries will be filtered according to $lib_region_filter_criteria_path
   --lib_region_filter_criteria_path               <optional> [string]  a list of library and region specific cutoffs for filtering valid tssCluster.
                                                                        if nothing is specified for a given pair library and region, a logistic probality 0.5 will be the only cutoff.
                                                                        The information must be formatted as the following
                                                                        $libID<\t>$filter_string
                                                                        $libID = Unique ID of the lib
                                                                        $filter_string = a formated string encoded the filtering criteria of tssCluster for each library, 
                                                                        in format of: 
                                                                        r[$regn]|t[$totc]|m[$maxc]|u[$ungc]|p[$prob],
                                                                        regn = region category, as end5:as, end5:ss, exon:as, exon:ss, intergenic:ns, intron:as, intron:ss
                                                                        totc = minimum total umi/read count [default 3]
                                                                        maxc = minimum max (summit) umi/read count [default 0]
                                                                        ungc = minimum unencoded G umi/read count [default 2]
                                                                        prob = minimum logistic probality [default 0.5]
                                                                        
                                                                        e.g.r[intron:ss]|t[5]|m[3]|u[3]|p[0.75]
                                                                        refers to tssClusters in sense orientation of intron (intron:ss) must have 
                                                                        minimum total umi/read count of 5,
                                                                        minimum max (summit) umi/read count of 3,
                                                                        minimum unencoded G umi/read count of 3,
                                                                        minimum logistic probality of 0.75,
                                                                        
                                                                        multiple region categories can be multiplexed by "," delimitation
                                                                        e.g. r[intron:ss,exon:ss]|t[5]|m[3]|u[3]|p[0.75]
                                                                        will apply the above criteria to both intron:ss and exon:ss
 
                                                                        you can specify only a subset of 4 criteria, default values will be used if not specified, 
                                                                        e.g. r[intron:ss,exon:ss]|p[0.75]
                                                                        will apply on the the prob criteria of 0.75 to intron:ss and exon:ss
 
                                                                        you can also skip the r to apply to all regions, 
                                                                        e.g. p[0.75]
                                                                        it will apply the prob criteria 0.75 to all regions
                                                                        
                                                                        multiple filter_string can be multiplexed by ";" delimitation
                                                                        e.g. r[intron:ss]|t[5]|m[3]|u[3]|p[0.75];r[exon:ss]|p[0.9]
   --outputPrefix                                  <required> [string]  prefix for the output files
   --outDir                                        <required> [string]  directory for the output files
   --overwrite                                     (optional) [yes/no]  erase outDir/outputPrefix before running (default=no)

 Dependencies:
   bedtools
   tabix
   bgzip
   
 For demo, cd to SCAFE dir and run,
   ./scafe.tool.cm.merge.pl \
   --overwrite=yes \
   --lib_list_path=XXX \
   --lib_region_filter_criteria_path=XXX \
   --aggregated_collapse_ctss_bed_path=XXX \
   --aggregated_unencoded_G_collapse_ctss_bed_path=XXX \
   --outputPrefix=XXX \
   --outDir=XXX

=head1 VERSION

v1.0.1 [May 9, 2023]
	-Initial release
 
=cut
#<\doc>
#====================================================================================================================================================#

#====================================================================================================================================================#
#<lastCmdCalled>
#
#	notCalledBefore
#
#	notCalledBefore
#
#<\lastCmdCalled>
#====================================================================================================================================================#

#====================================================================================================================================================#
#<global>
my $scriptDirPath = dirname(rel2abs($0));
my $scriptAbsPath = abs_path($0);
my ($curntTimeStamp) = &timeStamp();#->1738
my $ARGVStr = join "\n", (&currentTime(), $scriptAbsPath, @ARGV);#->534
my $globalReadmeHsh_ref = {};
our $tmplog_fh;
#<\global>
#====================================================================================================================================================#

#====================================================================================================================================================#
{	#Main sections lexical scope starts
#====================================================================================================================================================#

#====================================================================================================================================================#
#	section 0_startingTasks
#
#<section ID="startingTasks" num="0">
my ($lib_list_path, $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $lib_region_filter_criteria_path, $merge_dist, $min_ung_count, $min_count, $min_ung_num_pos, $min_num_pos, $min_ung_max, $min_max, $min_ung_at_total_summit, $genome, $force_retain_CRE_bed, $summit_flank_size, $summit_dnStrm_size, $max_summit_dnStrm_A_frac, $max_flank_A_frac, $A_stretch_length_length, $outputPrefix, $outDir, $overwrite) = &readParameters();#->1635
#<\section>
#====================================================================================================================================================#

#====================================================================================================================================================#
#	section 1_defineHardCodedParam
#
#<section ID="defineHardCodedParam" num="1">
my $paramTag = "$outputPrefix";
my $anno_reg_assignment_flank_size = 75;
my $force_retain_min_prob = 0.95;
$summit_flank_size = $summit_dnStrm_size if $summit_flank_size < $summit_dnStrm_size;#---[2023/05/15 12:37] enforce minimum 10 nt
my $default_cutoff_hsh_ref = {
	'r' => ['end5:as', 'end5:ss', 'exon:as', 'exon:ss', 'intergenic:ns', 'intron:as', 'intron:ss'], #regn = region category, as end5:as, end5:ss, exon:as, exon:ss, intergenic:ns, intron:as, intron:ss
	'param' => {
		't' => 3, #totc = minimum total umi/read count [default 3]
		'm' => 0, #maxc = minimum max (summit) umi/read count [default 0]
		'u' => 2, #ungc = minimum unencoded G umi/read count [default 2]
		'p' => 0.5, #prob = minimum logistic probality [default 0.5]
	},
};
#<\section>
#====================================================================================================================================================#

#====================================================================================================================================================#
#	section 2_defineOutDirPath
#
#<section ID="defineOutDirPath" num="2">
my @mkDirAry;
my $result_dir = "$outDir/$paramTag"; push @mkDirAry, $result_dir;
system "rm -rf $result_dir" if ($overwrite eq 'yes');
my $result_bed_dir = "$result_dir/bed/"; push @mkDirAry, $result_bed_dir;
my $result_log_dir = "$result_dir/log/"; push @mkDirAry, $result_log_dir;
my $result_tmp_dir = "$result_dir/tmp/"; push @mkDirAry, $result_tmp_dir;
my $indiv_lib_bed_dir = "$result_bed_dir/indiv_lib_bed"; push @mkDirAry, $indiv_lib_bed_dir;
my $result_script_dir = "$result_dir/script/"; push @mkDirAry, $result_script_dir;
foreach my $dir (@mkDirAry) {system ("mkdir -pm 755 $dir");}
open $tmplog_fh, ">", "$result_dir/00_screen_log.$curntTimeStamp.log.txt";
&logCalledCMDAndScript($ARGVStr, $result_script_dir, $scriptAbsPath);#->1036
&printStartOrFinishMessage("startMessage");#->1261
my ($tabix_bin, $bgzip_bin, $bedtools_bin, $samtools_bin, $paraclu_bin, $cut_sh_path, $bedGraphToBigWig_bin, $bigWigAverageOverBed_bin) = &checkAllExecutable();#->393
#<\section>
#====================================================================================================================================================#

#====================================================================================================================================================#
#	section 3_generate_chunk
#
#<section ID="generate_chunk" num="3">
&reportAndLogStatus("setting merge_dist = $merge_dist", 10, "\n");#->1716
&reportAndLogStatus("setting min_ung_count = $min_ung_count", 10, "\n");#->1716
&reportAndLogStatus("setting min_count = $min_count", 10, "\n");#->1716
&reportAndLogStatus("setting min_ung_num_pos = $min_ung_num_pos", 10, "\n");#->1716
&reportAndLogStatus("setting min_num_pos = $min_num_pos", 10, "\n");#->1716
&reportAndLogStatus("setting min_ung_max = $min_ung_max", 10, "\n");#->1716
&reportAndLogStatus("setting min_max = $min_max", 10, "\n");#->1716
&reportAndLogStatus("setting min_ung_at_total_summit = $min_ung_at_total_summit", 10, "\n");#->1716
&reportAndLogStatus("setting summit_dnStrm_size = $summit_dnStrm_size", 10, "\n");#->1716
&reportAndLogStatus("setting max_summit_dnStrm_A_frac = $max_summit_dnStrm_A_frac", 10, "\n");#->1716
my ($lib_info_hsh_ref) = &readLibInfo($lib_list_path);#->1607
&readLibCutoff($lib_info_hsh_ref, $default_cutoff_hsh_ref, $lib_region_filter_criteria_path, $result_log_dir, $paramTag);#->1498
#<\section>
#====================================================================================================================================================#

#====================================================================================================================================================#
#	section 4_merge
#
#<section ID="merge" num="4">
my ($mask_tss_region_bed_path, $exon_region_bed_path, $intron_region_bed_path, $background_exon_bed_path, $background_intron_bed_path, $gene_bed_path, $mask_bed_path, $chrom_size_path, $gene_info_path, $tss_pos_bed_path, $genome_fasta_path) = &checkRegionBedChromSizeGeneInfoPath($genome);#->493
my ($chrom_size_hsh_ref) = &getChromSizeHsh($chrom_size_path);#->789
&filterLibTssCluster($lib_info_hsh_ref, $indiv_lib_bed_dir);#->552
my ($tmp_merged_bed_path, $tssCluster_info_hsh_ref) = &mergeTssClusters($lib_info_hsh_ref, $result_tmp_dir, $bedtools_bin, $merge_dist);#->1061
&getTssClusterCount($tssCluster_info_hsh_ref, $tmp_merged_bed_path, $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $bedtools_bin);#->951
&getClusterSequence($tssCluster_info_hsh_ref, $result_tmp_dir, $chrom_size_hsh_ref, $genome_fasta_path, $summit_flank_size, $summit_dnStrm_size, $bedtools_bin);#->814
&assignTssClusterToAnnnotationRegions($anno_reg_assignment_flank_size, $bedtools_bin, $tssCluster_info_hsh_ref, $exon_region_bed_path, $intron_region_bed_path, $mask_tss_region_bed_path, $chrom_size_hsh_ref, $result_tmp_dir);#->285
&forceRetainCRE($tssCluster_info_hsh_ref, $force_retain_CRE_bed, $force_retain_min_prob, $bedtools_bin, $result_tmp_dir);#->740
&filterMergedTssCluster($tssCluster_info_hsh_ref, $min_ung_count, $min_count, $min_ung_num_pos, $min_num_pos, $min_ung_max, $min_max, $min_ung_at_total_summit, $max_summit_dnStrm_A_frac, $max_flank_A_frac, $A_stretch_length_length, $result_bed_dir, $paramTag);#->626
&printTssClusterBed($result_bed_dir, $tssCluster_info_hsh_ref, $paramTag);#->1295
&printTssClusterLog($result_log_dir, $tssCluster_info_hsh_ref, $paramTag);#->1344
#<\section>
#====================================================================================================================================================#

#====================================================================================================================================================#
#	section 5_finishingTasks
#
#<section ID="finishingTasks" num="5">
&printOutputFileListAndReadme($ARGVStr, $paramTag, $outDir);#->1146
&printStartOrFinishMessage("finishMessage");#->1261
#<\section>
#====================================================================================================================================================#

#====================================================================================================================================================#
}	#Main sections lexical scope ends
#====================================================================================================================================================#

#====================================================================================================================================================#
#List of subroutines by category
#
#	general [n=5]:
#		currentTime, logCalledCMDAndScript, printStartOrFinishMessage
#		readParameters, timeStamp
#
#	log [n=1]:
#		reportAndLogStatus
#
#	output [n=1]:
#		printOutputFileListAndReadme
#
#	time [n=1]:
#		timeStamp
#
#	unassigned [n=14]:
#		assignTssClusterToAnnnotationRegions, checkAllExecutable, checkRegionBedChromSizeGeneInfoPath
#		filterLibTssCluster, filterMergedTssCluster, forceRetainCRE
#		getChromSizeHsh, getClusterSequence, getTssClusterCount
#		mergeTssClusters, printTssClusterBed, printTssClusterLog
#		readLibCutoff, readLibInfo
#
#====================================================================================================================================================#

sub assignTssClusterToAnnnotationRegions {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $anno_reg_assignment_flank_size, $bedtools_bin, $chrom_size_hsh_ref, $exon_region_bed_path, $intron_region_bed_path, $mask_tss_region_bed_path, $result_tmp_dir, $tssCluster_info_hsh_ref
#	output: 
#	toCall: &assignTssClusterToAnnnotationRegions($anno_reg_assignment_flank_size, $bedtools_bin, $tssCluster_info_hsh_ref, $exon_region_bed_path, $intron_region_bed_path, $mask_tss_region_bed_path, $chrom_size_hsh_ref, $result_tmp_dir);
#	calledInLine: 238
#....................................................................................................................................................#
	my ($anno_reg_assignment_flank_size, $bedtools_bin, $tssCluster_info_hsh_ref, $exon_region_bed_path, $intron_region_bed_path, $mask_tss_region_bed_path, $chrom_size_hsh_ref, $result_tmp_dir) = @_;
	
	my $tssCluster_summit_anno_flank_bed_path = "$result_tmp_dir/tssCluster_summit_anno_flank.bed.gz";
	open SUMMITFLANKINGANNOBED, "| sort -k1,1 -k2,2n -k6,6 | gzip -c >$tssCluster_summit_anno_flank_bed_path";
	foreach my $tssClusterID (keys %{$tssCluster_info_hsh_ref}) {
		my $strand = $tssCluster_info_hsh_ref->{$tssClusterID}{'strand'};
		my $chrom = $tssCluster_info_hsh_ref->{$tssClusterID}{'chrom'};
		my $summit = $tssCluster_info_hsh_ref->{$tssClusterID}{'summit'};
		my $chromStart = $summit - $anno_reg_assignment_flank_size - 1;
		my $chromEnd = $summit + $anno_reg_assignment_flank_size;
		$chromStart = 0 if $chromStart < 0;
		$chromEnd = $chrom_size_hsh_ref->{$chrom} if $chromEnd > $chrom_size_hsh_ref->{$chrom};
		print SUMMITFLANKINGANNOBED join "", (join "\t", ($chrom, $chromStart, $chromEnd, $tssClusterID, '1', $strand)), "\n";
	}
	close SUMMITFLANKINGANNOBED;

	&reportAndLogStatus("Assigning background regions to tssClusters by summit location", 10, "\n");#->1716

	my $anno_info_hsh_ref = {};
	$anno_info_hsh_ref->{'end5'}{'bed_path'} = $mask_tss_region_bed_path;
	$anno_info_hsh_ref->{'end5'}{'priority'} = 0;
	$anno_info_hsh_ref->{'exon'}{'bed_path'} = $exon_region_bed_path;
	$anno_info_hsh_ref->{'exon'}{'priority'} = 1;
	$anno_info_hsh_ref->{'intron'}{'bed_path'} = $intron_region_bed_path;
	$anno_info_hsh_ref->{'intron'}{'priority'} = 2;
		
	my $check_tssClusterID_hsh_ref = {};

	my $anno_orientation_hsh_ref = {
		'ss' => '-s',
		'as' => '-S',
	};

	#---[2020/05/03 17:22] intersect annotation in order of ss, annotation priority then as, annotation priority
	foreach my $anno_orientation (qw/ss as/) {
		my $anno_orientation_opt = $anno_orientation_hsh_ref->{$anno_orientation};
		foreach my $anno_type (sort {$anno_info_hsh_ref->{$a}{'priority'} <=> $anno_info_hsh_ref->{$b}{'priority'}} keys %{$anno_info_hsh_ref}) {
			&reportAndLogStatus("Intersecting tssClusters with $anno_type in $anno_orientation anno_orientation.", 10, "\n");#->1716
			#---[2019/12/22 23:10] to hold the tssClusterID within this round
			my $anno_bed_path = $anno_info_hsh_ref->{$anno_type}{'bed_path'};
			my $within_region_tssClusterID_hsh_ref = {};
	
			open BEDTOOLSINTERSECT, "$bedtools_bin intersect $anno_orientation_opt -wo -a $tssCluster_summit_anno_flank_bed_path -b $anno_bed_path |";
			while (<BEDTOOLSINTERSECT>) {
				#chr1	11888638	11888649	chr1_11888638_11888649_+	25	+	chr1	11888514	11888681	ENSG00000011021.17;ENSG00000242349.1	2	+	11
				chomp;
				my @splt = split /\t/;
				my $tssClusterID = $splt[3];
				my $geneID_str = $splt[-4];
	
				#---[2019/12/22 23:11] skip if exists in previous round
				next if exists $check_tssClusterID_hsh_ref->{$tssClusterID};
	
				foreach my $geneID ((split /;/, $geneID_str)) {
					$tssCluster_info_hsh_ref->{$tssClusterID}{'anno_type'} = $anno_type;
					$tssCluster_info_hsh_ref->{$tssClusterID}{'anno_orientation'} = $anno_orientation;
					$tssCluster_info_hsh_ref->{$tssClusterID}{'anno_geneID'}{$geneID}++;
					$within_region_tssClusterID_hsh_ref->{$tssClusterID}++;
				}
			}
			close BEDTOOLSINTERSECT;
			my $num_tssCluster_within_region = keys %{$within_region_tssClusterID_hsh_ref};
			&reportAndLogStatus("$num_tssCluster_within_region tssClusters assigned to $anno_type in $anno_orientation anno_orientation.", 10, "\n");#->1716
			#---[2019/12/22 23:10] bookmark the added tssClusterID
			foreach my $tssClusterID (keys %{$within_region_tssClusterID_hsh_ref}) {
				$check_tssClusterID_hsh_ref->{$tssClusterID}++;
			}
		}
	}

	{
		&reportAndLogStatus("adding intergenic annotaton", 10, "\n");#->1716
		my $anno_type = 'intergenic';
		my $anno_orientation = 'ns';
		my $geneID = 'nongenic';
		my $num_tssCluster_within_region = 0;
		foreach my $tssClusterID (keys %{$tssCluster_info_hsh_ref}) {
			if (not exists $tssCluster_info_hsh_ref->{$tssClusterID}{'anno_type'}) {
				$num_tssCluster_within_region++;
				$tssCluster_info_hsh_ref->{$tssClusterID}{'anno_type'} = $anno_type;
				$tssCluster_info_hsh_ref->{$tssClusterID}{'anno_orientation'} = $anno_orientation;
				$tssCluster_info_hsh_ref->{$tssClusterID}{'anno_geneID'}{$geneID}++;
			}
		}
		&reportAndLogStatus("$num_tssCluster_within_region tssClusters assigned to $anno_type in $anno_orientation anno_orientation.", 10, "\n");#->1716
		
	}

	foreach my $tssClusterID (keys %{$tssCluster_info_hsh_ref}) {
		my $anno_type = $tssCluster_info_hsh_ref->{$tssClusterID}{'anno_type'};
		my $anno_orientation = $tssCluster_info_hsh_ref->{$tssClusterID}{'anno_orientation'};
		$tssCluster_info_hsh_ref->{$tssClusterID}{'anno_region'} = join ":", ($anno_type,$anno_orientation);
	}

	return ();
}
sub checkAllExecutable {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 2_defineOutDirPath|190
#	secondaryAppearInSection: >none
#	input: none
#	output: $bedGraphToBigWig_bin, $bedtools_bin, $bgzip_bin, $bigWigAverageOverBed_bin, $cut_sh_path, $paraclu_bin, $samtools_bin, $tabix_bin
#	toCall: my ($tabix_bin, $bgzip_bin, $bedtools_bin, $samtools_bin, $paraclu_bin, $cut_sh_path, $bedGraphToBigWig_bin, $bigWigAverageOverBed_bin) = &checkAllExecutable();
#	calledInLine: 205
#....................................................................................................................................................#
	
	my $dirPath = dirname(rel2abs($0));

	my $tabix_bin = "$dirPath/../resources/bin/tabix/tabix";
	my $bgzip_bin = "$dirPath/../resources/bin/bgzip/bgzip";
	my $bedtools_bin = "$dirPath/../resources/bin/bedtools/bedtools";
	my $samtools_bin = "$dirPath/../resources/bin/samtools/samtools";
	my $paraclu_bin = "$dirPath/../resources/bin/paraclu/paraclu";
	my $cut_sh_path = "$dirPath/../resources/bin/paraclu/paraclu-cut.sh";
	my $bedGraphToBigWig_bin = "$dirPath/../resources/bin/bedGraphToBigWig/bedGraphToBigWig";
	my $bigWigAverageOverBed_bin = "$dirPath/../resources/bin/bigWigAverageOverBed/bigWigAverageOverBed";
	
	&reportAndLogStatus("Checking all SCAFE executables", 10, "\n");#->1716
	
	{
		my $stdOut = `$tabix_bin  --version 2>&1`;
		if ($stdOut =~ m/tabix \(htslib\) (\S+)/) {
			&reportAndLogStatus("Checking: tabix version: $1", 0, "\n");#->1716
		} else {
			die "tabix is not installed properly. Quitting.\n";
		}
	}

	{
		my $stdOut = `$bgzip_bin --version 2>&1`;
		if ($stdOut =~ m/bgzip \(htslib\) (\S+)/) {
			&reportAndLogStatus("Checking: bgzip version: $1", 0, "\n");#->1716
		} else {
			die "bgzip is not installed properly. Quitting.\n";
		}
	}

	{
		my $stdOut = `$bedtools_bin --version 2>&1`;
		if ($stdOut =~ m/bedtools v(\S+)/) {
			&reportAndLogStatus("Checking: bedtools version: $1", 0, "\n");#->1716
		} else {
			die "bedtools is not installed properly. Quitting.\n";
		}
	}

	{
		my $stdOut = `$samtools_bin 2>&1`;
		if ($stdOut =~ m/\s+(Version: \S+)\s+/) {
			&reportAndLogStatus("Checking: samtools version: $1", 0, "\n");#->1716
		} else {
			die "samtools is not installed properly. Quitting.\n";
		}
	}
	
	{
		my $stdOut = `$paraclu_bin 2>&1`;
		if ($stdOut =~ m/paraclu: I need a minValue and a fileName/) {
			&reportAndLogStatus("Checking: paraclu found.", 0, "\n");#->1716
		} else {
			die "paraclu is not installed properly. Quitting.\n";
		}
	}
	
	{
		my $stdOut = `$cut_sh_path 55C7128A 2>&1`;
		if ($stdOut =~ m/awk:/) {
			&reportAndLogStatus("Checking: paraclu-cut found.", 0, "\n");#->1716
		} else {
			die "paraclu-cut is not installed properly. Quitting.\n";
		}
	}

	{
		my $stdOut = `$bedGraphToBigWig_bin 2>&1`;
		if ($stdOut =~ m/bedGraphToBigWig v (\S+)/) {
			&reportAndLogStatus("Checking: bedGraphToBigWig version: $1", 0, "\n");#->1716
		} else {
			die "bedGraphToBigWig not installed properly. Quitting.\n";
		}
	}

	{
		my $stdOut = `$bigWigAverageOverBed_bin 2>&1`;
		if ($stdOut =~ m/bigWigAverageOverBed v(\S+)/) {
			&reportAndLogStatus("Checking: bigWigAverageOverBed version: $1", 0, "\n");#->1716
		} else {
			die "bigWigAverageOverBed is not installed properly. Quitting.\n";
		}
	}

	return ($tabix_bin, $bgzip_bin, $bedtools_bin, $samtools_bin, $paraclu_bin, $cut_sh_path, $bedGraphToBigWig_bin, $bigWigAverageOverBed_bin);
}
sub checkRegionBedChromSizeGeneInfoPath {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: >none
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $genome
#	output: $background_exon_bed_path, $background_intron_bed_path, $chrom_size_path, $exon_region_bed_path, $gene_bed_path, $gene_info_path, $genome_fasta_path, $intron_region_bed_path, $mask_bed_path, $mask_tss_region_bed_path, $tss_pos_bed_path
#	toCall: my ($mask_tss_region_bed_path, $exon_region_bed_path, $intron_region_bed_path, $background_exon_bed_path, $background_intron_bed_path, $gene_bed_path, $mask_bed_path, $chrom_size_path, $gene_info_path, $tss_pos_bed_path, $genome_fasta_path) = &checkRegionBedChromSizeGeneInfoPath($genome);
#	calledInLine: 232
#....................................................................................................................................................#
	my ($genome) = @_;

	my $dirPath = dirname(rel2abs($0));
	my $mask_tss_region_bed_path = "$dirPath/../resources/genome/$genome/bed/TSS_flank_250.bed.gz";
	my $exon_region_bed_path = "$dirPath/../resources/genome/$genome/bed/exon.bed.gz";
	my $intron_region_bed_path = "$dirPath/../resources/genome/$genome/bed/intron.bed.gz";
	my $gene_bed_path = "$dirPath/../resources/genome/$genome/bed/gene.bed.gz";
	my $background_exon_bed_path = "$dirPath/../resources/genome/$genome/bed/exon.trnscpt_based.subtract_TSS_flank_250.bed.gz";
	my $background_intron_bed_path = "$dirPath/../resources/genome/$genome/bed/intron.trnscpt_based.subtract_TSS_flank_250.bed.gz";
	my $mask_bed_path = "$dirPath/../resources/genome/$genome/bed/mask.bed.gz";
	my $gene_info_path = "$dirPath/../resources/genome/$genome/tsv//gene.info.tsv";
	my $chrom_size_path = "$dirPath/../resources/genome/$genome/tsv/chrom.sizes.tsv";
	my $tss_pos_bed_path = "$dirPath/../resources/genome/$genome/bed/TSS_flank_0.bed.gz";
	my $genome_fasta_path = "$dirPath/../resources/genome/$genome/fasta/genome.fa";

	die "genome $genome does not have mask_tss_region_bed_path. Please rerun prep_genome step\n" if not -s $mask_tss_region_bed_path;
	die "genome $genome does not have exon_region_bed_path. Please rerun prep_genome step\n" if not -s $exon_region_bed_path;
	die "genome $genome does not have intron_region_bed_path. Please rerun prep_genome step\n" if not -s $intron_region_bed_path;
	die "genome $genome does not have background_exon_bed_path. Please rerun prep_genome step\n" if not -s $background_exon_bed_path;
	die "genome $genome does not have background_intron_bed_path. Please rerun prep_genome step\n" if not -s $background_intron_bed_path;
	die "genome $genome does not have mask_bed_path. Please rerun prep_genome step\n" if not -s $mask_bed_path;
	die "genome $genome does not have gene_info_path. Please rerun prep_genome step\n" if not -s $gene_info_path;
	die "genome $genome does not have chrom_size_path. Please rerun prep_genome step\n" if not -s $chrom_size_path;
	die "genome $genome does not have tss_pos_bed_path. Please rerun prep_genome step\n" if not -s $tss_pos_bed_path;
	die "genome $genome does not have gene_bed_path. Please rerun prep_genome step\n" if not -s $gene_bed_path;
	die "genome $genome does not have genome_fasta_path. Please rerun prep_genome step\n" if not -s $genome_fasta_path;

	return ($mask_tss_region_bed_path, $exon_region_bed_path, $intron_region_bed_path, $background_exon_bed_path, $background_intron_bed_path, $gene_bed_path, $mask_bed_path, $chrom_size_path, $gene_info_path, $tss_pos_bed_path, $genome_fasta_path);
}
sub currentTime {
#....................................................................................................................................................#
#	subroutineCategory: general
#	dependOnSub: >none
#	appearInSub: printStartOrFinishMessage|1261, reportAndLogStatus|1716
#	primaryAppearInSection: >none
#	secondaryAppearInSection: 2_defineOutDirPath|190, 3_generate_chunk|210, 5_finishingTasks|247
#	input: none
#	output: $runTime
#	toCall: my ($runTime) = &currentTime();
#	calledInLine: 151, 1277, 1281, 1286, 1290, 1732, 1733
#....................................................................................................................................................#
	
	my ($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst)=localtime(time);
	my $runTime = sprintf "%04d-%02d-%02d %02d:%02d", $year+1900, $mon+1,$mday,$hour,$min;	
	
	return $runTime;
}
sub filterLibTssCluster {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $indiv_lib_bed_dir, $lib_info_hsh_ref
#	output: 
#	toCall: &filterLibTssCluster($lib_info_hsh_ref, $indiv_lib_bed_dir);
#	calledInLine: 234
#....................................................................................................................................................#
	my ($lib_info_hsh_ref, $indiv_lib_bed_dir) = @_;
	
	foreach my $libID (keys %{$lib_info_hsh_ref}) {
		my $lib_filtered_tssCluster_bed = "$indiv_lib_bed_dir/$libID.filtered_tssCluster.bed.gz";
		$lib_info_hsh_ref->{$libID}{'lib_filtered_tssCluster_bed'} = $lib_filtered_tssCluster_bed;
		my $tssCluster_filter_log_path = $lib_info_hsh_ref->{$libID}{'tssCluster_filter_log_path'};
		my $tssCluster_all_bed_path = $lib_info_hsh_ref->{$libID}{'tssCluster_all_bed_path'};
		
		if ($tssCluster_filter_log_path =~ m/\.gz$/) {
			open (INLOG, " gzip -dc $tssCluster_filter_log_path|");
		} else {
			open (INLOG, "<", $tssCluster_filter_log_path);
		}
		<INLOG>;
		my $valid_tssCluster_hsh_ref = {};
		my $num_valid = 0; 
		my $num_total = 0; 
		while (<INLOG>) {
			#tssClusterID	prob	pass_default_cutoff	pass_robust_cutoff	pass_lenient_cutoff	chrom	strand	summit	anno_region	bkgd_region	bkgd_geneID	density	size	local_bkgd_count	local_bkgd_size	max	count	flank_count	bkgd_rltv_expr	ung_count	ung_pct	dist_to_anno_tss	dist_to_anno_cre	train_bwscore	test_bwscore
			#chr10_100009860_100009889_-	0.99923906879182	yes	yes	yes	chr10	-	100009882	end5:ss	exon:ss	ENSG00000107554.17	4.23e-02	29	1	653	8	40	382	5.91e+00	24	60.00	65	0	-1	-1
			#chr10_100009891_100010079_-	0.998324148391753	yes	yes	yes	chr10	-	100009919	end5:ss	exon:ss	ENSG00000107554.17	4.23e-02	188	1	653	68	358	385	5.92e+00	185	51.68	28	0	-1	-1
			#chr10_100150561_100150582_-	0.141215929871801	no	no	yes	chr10	-	100150565	exon:ss	exon:ss	ENSG00000107566.14	6.93e-02	21	77	1001	6	17	27	1.38e+00	3	17.65	6569	135	-1	-1
			#chr10_100167700_100167727_-	0.99931489224365	yes	yes	yes	chr10	-	100167701	intron:ss	intron:ss	ENSG00000107566.14	7.94e-03	27	5	1001	2	7	7	2.56e+00	7	100.00	18328	0	-1	-1
			#chr10_100182754_100182762_-	0.946211092114683	yes	no	yes	chr10	-	100182755	intron:ss	intron:ss	ENSG00000107566.14	7.94e-03	8	34	1001	2	4	4	1.75e+00	3	75.00	3274	55	-1	-1
			#chr10_100183551_100183621_-	0.53443728166915	yes	no	yes	chr10	-	100183552	intron:ss	intron:ss	ENSG00000107566.14	7.94e-03	70	15	1001	2	8	8	2.75e+00	3	37.50	2477	0	-1	-1
			#chr10_100185905_100186051_-	0.998566824033069	yes	yes	yes	chr10	-	100186029	end5:ss	exon:ss	ENSG00000107566.14	6.93e-02	146	12	649	195	708	722	6.12e+00	370	52.26	0	0	-1	-1
			#chr10_100186055_100186059_-	0.999381562686825	yes	yes	yes	chr10	-	100186057	end5:ss	exon:ss	ENSG00000107566.14	6.93e-02	4	12	649	19	27	702	6.08e+00	17	62.96	23	0	-1	-1
			#chr10_100186073_100186194_+	0.999861104242737	yes	yes	yes	chr10	+	100186141	end5:as	intergenic:ns	nongenic	0.016983016983017	121	17	1001	27	256	260	6.67e+00	156	60.94	3895	0	-1	-1
			#chr10_100186203_100186220_+	0.967270163161933	yes	yes	yes	chr10	+	100186220	end5:as	intergenic:ns	nongenic	0.157842157842158	17	158	1001	3	5	119	2.33e+00	3	60.00	3816	0	-1	-1
			chomp;
			my ($tssClusterID, $prob, $pass_default_cutoff, $pass_robust_cutoff, $pass_lenient_cutoff, $chrom, $strand, $summit, $anno_region, $bkgd_region, $bkgd_geneID, $density, $size, $local_bkgd_count, $local_bkgd_size, $max, $count, $flank_count, $bkgd_rltv_expr, $ung_count, $ung_pct, $dist_to_anno_tss, $dist_to_anno_cre, $train_bwscore, $test_bwscore) = split /\t/;
			$num_total++;
			if (
				$prob >= $lib_info_hsh_ref->{$libID}{'cutoff'}{$anno_region}{'p'} and
				$max >= $lib_info_hsh_ref->{$libID}{'cutoff'}{$anno_region}{'m'} and
				$count >= $lib_info_hsh_ref->{$libID}{'cutoff'}{$anno_region}{'t'} and
				$ung_count >= $lib_info_hsh_ref->{$libID}{'cutoff'}{$anno_region}{'u'}
			) {
				$valid_tssCluster_hsh_ref->{$tssClusterID} = sprintf "%.5f", $prob;
				$num_valid++;
			}
			&reportAndLogStatus("$num_valid of $num_total tssCluster is valid in $libID", 10, "\n") if $num_total%50000==0;#->1716
		}
		close INLOG;
		&reportAndLogStatus("$num_valid of $num_total tssCluster is valid in $libID", 10, "\n");#->1716
		
		open INBED, "gzip -dc $tssCluster_all_bed_path |";
		open OUTBED, "| sort -k1,1 -k2,2n | gzip -c >$lib_filtered_tssCluster_bed";
		while (<INBED>) {
			chomp;
			my ($chrom, $chromStart, $chromEnd, $tssClusterID, $score, $strand, $thickStart, $thickEnd, $itemRgb, $blockCount, $blockSizes, $blockStarts) = split /\t/;
			if (exists $valid_tssCluster_hsh_ref->{$tssClusterID}) {
				my $prob = $valid_tssCluster_hsh_ref->{$tssClusterID};
				print OUTBED join "", (join "\t", ($chrom, $chromStart, $chromEnd, $libID, $prob, $strand, $thickStart, $thickEnd, $itemRgb, $blockCount, $blockSizes, $blockStarts)), "\n";
			}
		}
		close OUTBED;
		close INBED;
	}

	return ();
}
sub filterMergedTssCluster {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $A_stretch_length_length, $max_flank_A_frac, $max_summit_dnStrm_A_frac, $min_count, $min_max, $min_num_pos, $min_ung_at_total_summit, $min_ung_count, $min_ung_max, $min_ung_num_pos, $paramTag, $result_bed_dir, $tssCluster_info_hsh_ref
#	output: 
#	toCall: &filterMergedTssCluster($tssCluster_info_hsh_ref, $min_ung_count, $min_count, $min_ung_num_pos, $min_num_pos, $min_ung_max, $min_max, $min_ung_at_total_summit, $max_summit_dnStrm_A_frac, $max_flank_A_frac, $A_stretch_length_length, $result_bed_dir, $paramTag);
#	calledInLine: 240
#....................................................................................................................................................#
	my ($tssCluster_info_hsh_ref, $min_ung_count, $min_count, $min_ung_num_pos, $min_num_pos, $min_ung_max, $min_max, $min_ung_at_total_summit, $max_summit_dnStrm_A_frac, $max_flank_A_frac, $A_stretch_length_length, $result_bed_dir, $paramTag) = @_;
	
	&reportAndLogStatus("Filtering merged tssClusters", 10, "\n");#->1716
	my $pre_filter_tssCluster_num = 0;
	my $post_filter_tssCluster_num = 0;
	foreach my $tssClusterID (keys %{$tssCluster_info_hsh_ref}) {
		$pre_filter_tssCluster_num++;
		my $valid = 'yes';
		my $anno_region = $tssCluster_info_hsh_ref->{$tssClusterID}{'anno_region'};
		my $ung_count = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_count'};
		my $count = $tssCluster_info_hsh_ref->{$tssClusterID}{'count'};
		my $ung_num_pos = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_num_pos'};
		my $num_pos = $tssCluster_info_hsh_ref->{$tssClusterID}{'num_pos'};
		my $ung_max = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_max'};
		my $max = $tssCluster_info_hsh_ref->{$tssClusterID}{'max'};
		my $ung_at_total_summit = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_at_total_summit'};
		my $ung_summit_dnStrm_A_frac = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summit_dnStrm_A_frac'};
		my $total_summit_dnStrm_A_frac = $tssCluster_info_hsh_ref->{$tssClusterID}{'total_summit_dnStrm_A_frac'};
		my $force_retain_CRE = $tssCluster_info_hsh_ref->{$tssClusterID}{'force_retain_CRE'};
		my $force_retain_prob = $tssCluster_info_hsh_ref->{$tssClusterID}{'force_retain_prob'};
		my $total_A_stretch_length = $tssCluster_info_hsh_ref->{$tssClusterID}{'total_A_stretch_length'};
		my $total_flank_A_frac = $tssCluster_info_hsh_ref->{$tssClusterID}{'total_flank_A_frac'};
		my $ung_A_stretch_length = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_A_stretch_length'};
		my $ung_flank_A_frac = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_flank_A_frac'};

		my $pass_lenient_count_cutoff = 'yes';
		my $pass_lenient_polyA_cutoff = 'yes';
		my $pass_stringent_count_cutoff = 'yes';
		my $pass_stringent_polyA_cutoff = 'yes';
		
		if ($ung_num_pos < 3) {
			$pass_lenient_count_cutoff = 'no';
		}

		if (
			$ung_count < $min_ung_count or 
			$count < $min_count or 
			$ung_num_pos < $min_ung_num_pos or 
			$num_pos < $min_num_pos or 
			$ung_max < $min_ung_max or 
			$max < $min_max or 
			$ung_at_total_summit < $min_ung_at_total_summit
		) {
				$pass_stringent_count_cutoff = 'no';
		}

		if (
			$ung_summit_dnStrm_A_frac >= $max_summit_dnStrm_A_frac or #---[2023/05/17 13:05] 0.8
			$total_summit_dnStrm_A_frac >= $max_summit_dnStrm_A_frac #---[2023/05/17 13:05] 0.8
		) {
			$pass_lenient_polyA_cutoff = 'no';
		}

		if (
			$ung_flank_A_frac >= $max_flank_A_frac or #---[2023/05/17 13:05] 0.75
			$ung_A_stretch_length >= $A_stretch_length_length or #---[2023/05/17 13:05] 20
			$total_flank_A_frac >= $max_flank_A_frac or #---[2023/05/17 13:05] 0.75
			$total_A_stretch_length >= $A_stretch_length_length #---[2023/05/17 13:05] 20
		) {
			$pass_stringent_polyA_cutoff = 'no';
		}


		#---[2023/05/17 13:06] univerisal criteria
		$valid = 'no' if $pass_lenient_count_cutoff eq 'no';

		#---[2023/05/17 11:54] polyA criteria
		if ($force_retain_CRE eq 'yes') {
			#---[2023/05/16 19:06] with CRE support, all will be protected 
		} else {

			if ($force_retain_prob eq 'no') {
				#---[2023/05/17 14:52] remove only if not protected by force_retain_prob
				$valid = 'no' if $pass_stringent_count_cutoff eq 'no';
			}

			if ($anno_region eq 'end5:ss' or $anno_region eq 'end5:as' or $anno_region eq 'intergenic:ns') {

					$valid = 'no' if $pass_lenient_polyA_cutoff eq 'no' and $pass_stringent_polyA_cutoff eq 'no';

			} elsif ($anno_region eq 'exon:ss' or $anno_region eq 'exon:as' or $anno_region eq 'intron:as' or $anno_region eq 'intron:ss') {

					$valid = 'no' if $pass_lenient_polyA_cutoff eq 'no';

			} else {
				die "Impossible anno_region $anno_region\n";
			}
		}

		$post_filter_tssCluster_num++ if $valid eq 'yes';
		$tssCluster_info_hsh_ref->{$tssClusterID}{'valid'} = $valid;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'pass_stringent_polyA_cutoff'} = $pass_stringent_polyA_cutoff;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'pass_stringent_count_cutoff'} = $pass_stringent_count_cutoff;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'pass_lenient_polyA_cutoff'} = $pass_lenient_polyA_cutoff;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'pass_lenient_count_cutoff'} = $pass_lenient_count_cutoff;
	}
	
	&reportAndLogStatus("$post_filter_tssCluster_num of $pre_filter_tssCluster_num cluster are retained.", 10, "\n");#->1716

	return ();
}
sub forceRetainCRE {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $bedtools_bin, $force_retain_CRE_bed, $force_retain_min_prob, $result_tmp_dir, $tssCluster_info_hsh_ref
#	output: 
#	toCall: &forceRetainCRE($tssCluster_info_hsh_ref, $force_retain_CRE_bed, $force_retain_min_prob, $bedtools_bin, $result_tmp_dir);
#	calledInLine: 239
#....................................................................................................................................................#
	my ($tssCluster_info_hsh_ref, $force_retain_CRE_bed, $force_retain_min_prob, $bedtools_bin, $result_tmp_dir) = @_;
	
	if (defined $force_retain_CRE_bed) {
		my $num_total = keys %{$tssCluster_info_hsh_ref};
		my $num_retained = 0;

		&reportAndLogStatus("force retaining tssClusters by CRE", 10, "\n");#->1716
		my $tssCluster_unfiltered_bed_path = "$result_tmp_dir/tssCluster_unfiltered.bed";
		open TSSCLUSTERBED, "| sort -k1,1 -k2,2n >$tssCluster_unfiltered_bed_path";
		foreach my $tssClusterID (keys %{$tssCluster_info_hsh_ref}) {

			my $chrom = $tssCluster_info_hsh_ref->{$tssClusterID}{'chrom'};
			my ($chromStart, $chromEnd) = @{$tssCluster_info_hsh_ref->{$tssClusterID}{'pos'}};
			my $strand = $tssCluster_info_hsh_ref->{$tssClusterID}{'strand'};
			my $prob = $tssCluster_info_hsh_ref->{$tssClusterID}{'prob'};
			$tssCluster_info_hsh_ref->{$tssClusterID}{'force_retain_prob'} = 'yes' if $prob >= $force_retain_min_prob;

			#my $summit = $tssCluster_info_hsh_ref->{$tssClusterID}{'summit'};
			#my $chromEnd = $summit;
			#my $chromStart = $chromEnd - 1;
			print TSSCLUSTERBED join "", (join "\t", ($chrom, $chromStart, $chromEnd, $tssClusterID, $prob, $strand)), "\n";
		}
		close TSSCLUSTERBED;

		open CREINTERSECT, "$bedtools_bin intersect -u -a $tssCluster_unfiltered_bed_path -b $force_retain_CRE_bed | cut -f 4 |";
		while (<CREINTERSECT>) {
			chomp;
			my ($tssClusterID) = $_;
			$num_retained++;
			$tssCluster_info_hsh_ref->{$tssClusterID}{'force_retain_CRE'} = 'yes';
		}
		close CREINTERSECT;
		&reportAndLogStatus("$num_retained of $num_total tssClusters were force retained", 10, "\n");#->1716
	}
	
	return ();
}
sub getChromSizeHsh {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: >none
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $chrom_size_path
#	output: $chrom_size_hsh_ref
#	toCall: my ($chrom_size_hsh_ref) = &getChromSizeHsh($chrom_size_path);
#	calledInLine: 233
#....................................................................................................................................................#
	my ($chrom_size_path) = @_;
	
	my $chrom_size_hsh_ref = {};
	open (CHROMSIZE, "<", $chrom_size_path);
	while (<CHROMSIZE>) {
		chomp;
		my ($chrom, $size) = split /\s+/;
		$chrom_size_hsh_ref->{$chrom} = $size;
	}
	close CHROMSIZE;
	
	return ($chrom_size_hsh_ref);
}
sub getClusterSequence {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $bedtools_bin, $chrom_size_hsh_ref, $genome_fasta_path, $result_tmp_dir, $summit_dnStrm_size, $summit_flank_size, $tssCluster_info_hsh_ref
#	output: 
#	toCall: &getClusterSequence($tssCluster_info_hsh_ref, $result_tmp_dir, $chrom_size_hsh_ref, $genome_fasta_path, $summit_flank_size, $summit_dnStrm_size, $bedtools_bin);
#	calledInLine: 237
#....................................................................................................................................................#
	my ($tssCluster_info_hsh_ref, $result_tmp_dir, $chrom_size_hsh_ref, $genome_fasta_path, $summit_flank_size, $summit_dnStrm_size, $bedtools_bin) = @_;
	
	my $dummy_flank_seq = '';
	foreach my $i (0..($summit_flank_size*2)) {
		$dummy_flank_seq .= 'N';
	}

	my $total_ung_hsh_ref = {
		'total' => {
			'bed' => "$result_tmp_dir/total.summit_flanking.bed",
			'fasta' => "$result_tmp_dir/total.summit_flanking.fasta",
			'key' => {
				'summit' => 'summit',
				'flank_seq' => 'total_summit_flank_seq',
				'dnStrm_seq' => 'total_summit_dnStrm_seq',
				'dnStrm_A_frac' => 'total_summit_dnStrm_A_frac',
				'A_stretch_length' => 'total_A_stretch_length',
				'flank_A_frac' => 'total_flank_A_frac',
			},
		},
		'ung' => {
			'bed' => "$result_tmp_dir/ung.summit_flanking.bed",
			'fasta' => "$result_tmp_dir/ung.summit_flanking.fasta",
			'key' => {
				'summit' => 'ung_summit',
				'flank_seq' => 'ung_summit_flank_seq',
				'dnStrm_seq' => 'ung_summit_dnStrm_seq',
				'dnStrm_A_frac' => 'ung_summit_dnStrm_A_frac',
				'A_stretch_length' => 'ung_A_stretch_length',
				'flank_A_frac' => 'ung_flank_A_frac',
			},
		},
	};
	
	foreach my $total_ung (keys %{$total_ung_hsh_ref}) {
		&reportAndLogStatus("Printing summit flanking bed for $total_ung ctss", 10, "\n");#->1716

		my $summit_flanking_bed = $total_ung_hsh_ref->{$total_ung}{'bed'};
		my $summit_flanking_fasta = $total_ung_hsh_ref->{$total_ung}{'fasta'};
		my $key_summit = $total_ung_hsh_ref->{$total_ung}{'key'}{'summit'};
		my $key_flank_seq = $total_ung_hsh_ref->{$total_ung}{'key'}{'flank_seq'};
		my $key_dnStrm_seq = $total_ung_hsh_ref->{$total_ung}{'key'}{'dnStrm_seq'};
		my $key_dnStrm_A_frac = $total_ung_hsh_ref->{$total_ung}{'key'}{'dnStrm_A_frac'};
		my $key_A_stretch_length = $total_ung_hsh_ref->{$total_ung}{'key'}{'A_stretch_length'};
		my $key_flank_A_frac = $total_ung_hsh_ref->{$total_ung}{'key'}{'flank_A_frac'};
		open SUMMITFLANKINGBED, "| sort -k1,1 -k2,2n >$summit_flanking_bed";
		foreach my $tssClusterID (keys %{$tssCluster_info_hsh_ref}) {
			
			#---[2023/05/15 11:40] store dummy sequence in case of out of bound
			$tssCluster_info_hsh_ref->{$tssClusterID}{$key_flank_seq} = $dummy_flank_seq;
			$tssCluster_info_hsh_ref->{$tssClusterID}{$key_dnStrm_A_frac} = 0;

			my $strand = $tssCluster_info_hsh_ref->{$tssClusterID}{'strand'};
			my $chrom = $tssCluster_info_hsh_ref->{$tssClusterID}{'chrom'};
			my $summit = $tssCluster_info_hsh_ref->{$tssClusterID}{$key_summit};
			my $chromStart = $summit - $summit_flank_size - 1;
			my $chromEnd = $summit + $summit_flank_size;
		
			if ($chromEnd < $chrom_size_hsh_ref->{$chrom} and $chromStart > 0) {#---[2023/05/15 0:32] prevent out of bound
				print SUMMITFLANKINGBED join "", (join "\t", ($chrom, $chromStart, $chromEnd, $tssClusterID, '1', $strand)), "\n";
			}
		}
		close SUMMITFLANKINGBED;

		&reportAndLogStatus("Getting summit flanking sequence for $total_ung ctss", 10, "\n");#->1716
		system "$bedtools_bin getfasta -s -name -fi $genome_fasta_path -bed $summit_flanking_bed -fo $summit_flanking_fasta";

		open SUMMITSEQ, "<", $summit_flanking_fasta;
		while (<SUMMITSEQ>) {
			#>chr1_29179_29370_-::chr1:29348-29369(-)
			#CCGGCAGAGCGGAAGCGGCGG
			#>chr1_181090_181261_-::chr1:181130-181151(-)
			#cggcggagttgcgttctcctc
			#>chr1_181338_181348_-::chr1:181337-181358(-)
			#tggacgcgctagcatgtgtct
		
			if ($_ =~ m/^>(chr.+)::/) {
				my $tssClusterID = $1;
				chomp (my $flank_seq = <SUMMITSEQ>);
				die if not exists $tssCluster_info_hsh_ref->{$tssClusterID};
				$flank_seq = uc($flank_seq);
				$tssCluster_info_hsh_ref->{$tssClusterID}{$key_flank_seq} = $flank_seq;
				my $dnStrm_seq = substr $flank_seq, $summit_flank_size+1, $summit_dnStrm_size;
				my $dnStrm_A_count = ($dnStrm_seq =~ tr/A//);
				my $dnStrm_A_frac = sprintf "%.3f", $dnStrm_A_count / $summit_dnStrm_size;
				my $flank_length = length($flank_seq);
				my $flank_A_count = ($flank_seq =~ tr/A//);
				my $flank_A_frac = sprintf "%.3f", $flank_A_count / $flank_length;

				my $max_length = 0;
				my $current_length = 0;
				my $allowed_mismatch = my $current_mismatch = 1;

				# Iterate through each character in the string
				for my $char (split //, $flank_seq) {
					if ($char eq 'A') {
						# If the character is 'A', increase the current length
						$current_length++;
					} else {
						# If the character is not 'A', decrement the mismatches allowed
						$current_mismatch--;
						if ($current_mismatch < 0) {
							# If the number of mismatches allowed is negative, reset the current length
							$current_length = 0;
							$current_mismatch = $allowed_mismatch;
						}
					}
					# Update the maximum length if the current length exceeds it
					$max_length = $current_length if $current_length > $max_length;
				}
				
				my $A_stretch_length = $max_length;
			
				$tssCluster_info_hsh_ref->{$tssClusterID}{$key_dnStrm_seq} = $dnStrm_seq;
				$tssCluster_info_hsh_ref->{$tssClusterID}{$key_dnStrm_A_frac} = $dnStrm_A_frac;
				$tssCluster_info_hsh_ref->{$tssClusterID}{$key_flank_A_frac} = $flank_A_frac;
				$tssCluster_info_hsh_ref->{$tssClusterID}{$key_A_stretch_length} = $A_stretch_length;
				
			}
		}
		close SUMMITSEQ;
	}
	
	return ();
}
sub getTssClusterCount {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $bedtools_bin, $tmp_merged_bed_path, $tssCluster_info_hsh_ref
#	output: 
#	toCall: &getTssClusterCount($tssCluster_info_hsh_ref, $tmp_merged_bed_path, $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $bedtools_bin);
#	calledInLine: 236
#....................................................................................................................................................#
	my ($tssCluster_info_hsh_ref, $tmp_merged_bed_path, $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $bedtools_bin) = @_;
	
	&reportAndLogStatus("Intersecting total ctss", 10, "\n");#->1716
	my $ctss_proc = 0;
	open BEDTOOLS, "$bedtools_bin intersect -sorted -s -wo -a $tmp_merged_bed_path -b $aggregated_collapse_ctss_bed_path |";
	while (<BEDTOOLS>) {
		chomp;
		my @splt = split /\t/;
		my $tssClusterID = $splt[3];
		my $pos = $splt[-5];
		my $count = $splt[-3];
		my $chrom = $splt[0];

		$tssCluster_info_hsh_ref->{$tssClusterID}{'count'} += $count;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ctss'}{$pos} = $count;

		if ($count >= $tssCluster_info_hsh_ref->{$tssClusterID}{'max'}) {
			$tssCluster_info_hsh_ref->{$tssClusterID}{'max'} = $count;
			$tssCluster_info_hsh_ref->{$tssClusterID}{'summit'} = $pos;
		}
		$ctss_proc++;
		&reportAndLogStatus("$ctss_proc ctss processed", 10, "\n") if $ctss_proc%100000 == 0;#->1716
	}
	close OUTBED;
	
	&reportAndLogStatus("Intersecting unencoded G ctss", 10, "\n");#->1716
	$ctss_proc = 0;
	#---[2023/05/13 15:48] make sure the position in aggregated_unencoded_G_collapse_ctss_bed_path is within aggregated_collapse_ctss_bed_path
	open BEDTOOLS, "$bedtools_bin intersect -sorted -s -a $aggregated_unencoded_G_collapse_ctss_bed_path -b $aggregated_collapse_ctss_bed_path | $bedtools_bin intersect -sorted -s -wo -a $tmp_merged_bed_path -b stdin |";
	while (<BEDTOOLS>) {
		chomp;
		my @splt = split /\t/;
		my $tssClusterID = $splt[3];
		my $pos = $splt[-5];
		my $count = $splt[-3];
		
		die "tssClusterID $tssClusterID exists in total ctss but not unencoded G ctss\n" if (not exists $tssCluster_info_hsh_ref->{$tssClusterID});
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_count'} += $count;;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_ctss'}{$pos} = $count;

		if ($count >= $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_max'}) {
			$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_max'} = $count;
			$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summit'} = $pos;
		}

		$ctss_proc++;
		&reportAndLogStatus("$ctss_proc ctss processed", 10, "\n") if $ctss_proc%100000 == 0;#->1716
	}
	close OUTBED;
	
	foreach my $tssClusterID (keys %{$tssCluster_info_hsh_ref}) {
		die "tssClusterID $tssClusterID does not have total ctss count\n" if not exists $tssCluster_info_hsh_ref->{$tssClusterID}{'ctss'};
		die "tssClusterID $tssClusterID does not have ung ctss count\n" if not exists $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_ctss'};
		my $ung_pct = sprintf "%.2f", 100*$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_count'}/$tssCluster_info_hsh_ref->{$tssClusterID}{'count'};
		die "unencoded G percentage of tssClusterID $tssClusterID is greater than 100. Check input ctss.\n" if $ung_pct > 100;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_pct'} = $ung_pct;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'num_pos'} = keys %{$tssCluster_info_hsh_ref->{$tssClusterID}{'ctss'}};
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_num_pos'} = keys %{$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_ctss'}};
		my $summit = $tssCluster_info_hsh_ref->{$tssClusterID}{'summit'};
		my $ung_summit = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summit'};
		
		if (exists $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_ctss'}{$summit}) {
			$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_at_total_summit'} = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_ctss'}{$summit};
		}
		
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summmit_ovrlp'} = 'no';
		if ($ung_summit eq $summit) {
			$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summmit_ovrlp'} = 'yes';
		}
	}
	
	return ();
}
sub logCalledCMDAndScript {
#....................................................................................................................................................#
#	subroutineCategory: general
#	dependOnSub: >none
#	appearInSub: >none
#	primaryAppearInSection: 2_defineOutDirPath|190
#	secondaryAppearInSection: >none
#	input: $ARGVStr, $result_script_dir, $scriptAbsPath
#	output: 
#	toCall: &logCalledCMDAndScript($ARGVStr, $result_script_dir, $scriptAbsPath);
#	calledInLine: 203
#....................................................................................................................................................#
	my ($ARGVStr, $result_script_dir, $scriptAbsPath) = @_;


	my $cpScriptPath = "$result_script_dir/script.ran.pl";
	my $calledCMDPath = "$result_script_dir/called.cmd.txt";
	system "cp -f $scriptAbsPath $cpScriptPath";
	system "chmod 0444 $cpScriptPath"; #---[07/03/2014 18:02] make it read-only to make sure there'll be accodental change of parameters
	open CALLEDCMD, ">", $calledCMDPath;
	print CALLEDCMD join "", ($ARGVStr), "\n";
	close CALLEDCMD;
	
	return ();
}
sub mergeTssClusters {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $bedtools_bin, $lib_info_hsh_ref, $merge_dist, $result_tmp_dir
#	output: $tmp_merged_bed_path, $tssCluster_info_hsh_ref
#	toCall: my ($tmp_merged_bed_path, $tssCluster_info_hsh_ref) = &mergeTssClusters($lib_info_hsh_ref, $result_tmp_dir, $bedtools_bin, $merge_dist);
#	calledInLine: 235
#....................................................................................................................................................#
	my ($lib_info_hsh_ref, $result_tmp_dir, $bedtools_bin, $merge_dist) = @_;
	
	my @indiv_bed_ary = ();
	foreach my $libID (sort keys %{$lib_info_hsh_ref}) {
		my $lib_filtered_tssCluster_bed = $lib_info_hsh_ref->{$libID}{'lib_filtered_tssCluster_bed'};
		push @indiv_bed_ary, $lib_filtered_tssCluster_bed;
	}
	my $tmp_base_bed_path = "$result_tmp_dir/tmp_base.bed.gz";
	my $tmp_merged_bed_path = "$result_tmp_dir/tmp_merged.bed.gz";
	my $tmp_sort_bed_path = "$result_tmp_dir/tmp_sort.bed";
	my $initial_bed_path = pop @indiv_bed_ary;
	
	#---[2023/05/12 18:00] set up the initial bed
	system "cp -f $initial_bed_path $tmp_base_bed_path";
	my $merge_round = 0;
	foreach my $overlay_bed_path (@indiv_bed_ary) {
		$merge_round++;
		&reportAndLogStatus("merging round $merge_round", 10, "\n");#->1716
		system ("zcat $tmp_base_bed_path $overlay_bed_path | sort -k1,1 -k2,2n >$tmp_sort_bed_path");
		system ("cut -f 1-6 $tmp_sort_bed_path | $bedtools_bin merge -d $merge_dist -s -i stdin -c 4,5,6 -o collapse,collapse,distinct | gzip -c >$tmp_merged_bed_path");
		system "mv -f $tmp_merged_bed_path $tmp_base_bed_path";
	}
	
	my $tssCluster_info_hsh_ref = {};
	open MERGEDBED, "| gzip -c >$tmp_merged_bed_path";
	open BASEBED, "gzip -dc $tmp_base_bed_path |";
	while (<BASEBED>) {
		chomp;
		my ($chrom, $chromStart, $chromEnd, $redundant_libID_str, $prob_str, $strand) = split /\t/;
		my $tssClusterID = join "_", ($chrom, $chromStart, $chromEnd, $strand);
		my $size = $chromEnd - $chromStart;
		my @prob_ary = split /\,/, $prob_str;
		my @redundant_libID_ary = split /\,/, $redundant_libID_str;
		my $prob = max(@prob_ary);
		my $num_cluster_merged = @redundant_libID_ary;
		my $libID_hsh_ref = {};
		foreach my $libID (@redundant_libID_ary) {
			$libID_hsh_ref->{$libID}++;
		}
		my @libID_ary = sort keys %{$libID_hsh_ref};
		my $libID_str = join ",", @libID_ary;
		my $num_lib = @libID_ary;
		
		$tssCluster_info_hsh_ref->{$tssClusterID}{'count'} = 0;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'max'} = 0;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'num_pos'} = 0;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_count'} = 0;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_max'} = 0;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_num_pos'} = 0;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'ung_at_total_summit'} = 0;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'strand'} = $strand;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'chrom'} = $chrom;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'size'} = $size;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'pos'} = [$chromStart, $chromEnd];
		$tssCluster_info_hsh_ref->{$tssClusterID}{'libID_str'} = $libID_str;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'prob_str'} = $prob_str;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'prob'} = $prob;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'num_lib'} = $num_lib;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'num_cluster_merged'} = $num_cluster_merged;
		$tssCluster_info_hsh_ref->{$tssClusterID}{'force_retain_CRE'} = 'no';
		$tssCluster_info_hsh_ref->{$tssClusterID}{'force_retain_prob'} = 'no';

		print MERGEDBED join "", (join "\t", ($chrom, $chromStart, $chromEnd, $tssClusterID, $prob, $strand)), "\n";
	}
	close BASEBED;
	close MERGEDBED;
	
	my $num_merged_cluster_before_filtering = keys %{$tssCluster_info_hsh_ref};
	&reportAndLogStatus("num_merged_cluster_before_filtering = $num_merged_cluster_before_filtering", 10, "\n");#->1716
	
	return ($tmp_merged_bed_path, $tssCluster_info_hsh_ref);

}
sub printOutputFileListAndReadme {
#....................................................................................................................................................#
#	subroutineCategory: output
#	dependOnSub: >none
#	appearInSub: >none
#	primaryAppearInSection: 5_finishingTasks|247
#	secondaryAppearInSection: >none
#	input: $ARGVStr, $outDir, $paramTag
#	output: 
#	toCall: &printOutputFileListAndReadme($ARGVStr, $paramTag, $outDir);
#	calledInLine: 250
#....................................................................................................................................................#
	my ($ARGVStr, $paramTag, $outDir) = @_;
	
	my $outputFileListPath = "$outDir/$paramTag/output.file.list.txt";
	open (OUTFILELIST, ">", $outputFileListPath);

	my %dirHsh = ();
	my %filelistLenCountHsh = ();
	push @{$filelistLenCountHsh{'dir'}}, length 'Directory';
	push @{$filelistLenCountHsh{'name'}}, length 'Name';
	push @{$filelistLenCountHsh{'description'}}, length 'Description';
	
	foreach my $outputFilePath (sort {$a cmp $b} keys %{$globalReadmeHsh_ref}) {
		my $fileDescription =  $globalReadmeHsh_ref->{$outputFilePath}{'description'};
		my $cleandOutputFilePath = $outputFilePath;
		$cleandOutputFilePath =~ s/\/+/\//g;
		
		my ($filePrefix, $fileDir, $fileSuffix) = fileparse($cleandOutputFilePath, qr/\.[^.]*/);
		$fileDir =~ s/^$outDir//;
		my $fileName = $filePrefix.$fileSuffix;
		$dirHsh{$fileDir}{$fileName} = $fileDescription;
		push @{$filelistLenCountHsh{'dir'}}, length $fileDir;
		push @{$filelistLenCountHsh{'name'}}, length $fileName;
		push @{$filelistLenCountHsh{'description'}}, length $fileDescription;
		
		open README, ">", "$outputFilePath.readme.txt";
		print README "=================\n";
		print README "File descriptions\n";
		print README "=================\n";
		print README "$fileDescription\n";
					
		if (exists $globalReadmeHsh_ref->{$outputFilePath}{'headerAry'}) {
			my @colLenCountHsh = (length 'column');
			push @colLenCountHsh, length $_ foreach (@{$globalReadmeHsh_ref->{$outputFilePath}{'headerAry'}});
			my $headerColLen = max(@colLenCountHsh)+2;
			print README "\n";
			print README "\n";
			print README "===================\n";
			print README "Column descriptions\n";
			print README "===================\n";
			print README "\n";
			printf README "%-".$headerColLen."s", 'column';
			print README "description\n";
			printf README "%-".$headerColLen."s", '------';
			print README "-----------\n";
			foreach my $header (@{$globalReadmeHsh_ref->{$outputFilePath}{'headerAry'}}) {
				my $columnDescription = 'self-explanatory';
				$columnDescription = $globalReadmeHsh_ref->{$outputFilePath}{'header'}{$header} if exists $globalReadmeHsh_ref->{$outputFilePath}{'header'}{$header};
				printf README "%-".$headerColLen."s", $header;
				print README $columnDescription."\n";
			}
		}
		
		if (exists $globalReadmeHsh_ref->{$outputFilePath}{'extra_info'}) {
			print README "\n";
			print README "\n";
			print README "=================\n";
			print README "Extra information\n";
			print README "=================\n";
			print README "\n";
			foreach my $title (sort keys %{$globalReadmeHsh_ref->{$outputFilePath}{'extra_info'}}) {
				print README "$title\n";
				print README "-" foreach (1..length $title);
				print README "\n";
				print README "$_\n" foreach @{$globalReadmeHsh_ref->{$outputFilePath}{'extra_info'}{$title}};
			}
		}
		
		print README "\n";
		print README "\n";
		print README "~" foreach (1..length "$fileName was created from running,");
		print README "\n";
		print README "$fileName was created from running,\n";
		print README "\n";
		print README "$ARGVStr\n";
		print README "\n";
		close README;
	}

	my $fileDir_colLen = max(@{$filelistLenCountHsh{'dir'}})+2;
	my $fileName_colLen = max(@{$filelistLenCountHsh{'name'}})+2;
	my $fileDescription_colLen = max(@{$filelistLenCountHsh{'description'}})+2;
	printf OUTFILELIST ("%-".$fileDir_colLen."s %-".$fileName_colLen."s %-".$fileDescription_colLen."s\n", 'directory', 'name', 'description');
	printf OUTFILELIST ("%-".$fileDir_colLen."s %-".$fileName_colLen."s %-".$fileDescription_colLen."s\n", '=========', '====', '===========');
	foreach my $fileDir (sort {$a cmp $b} keys %dirHsh) {
		foreach my $fileName (sort {$a cmp $b} keys %{$dirHsh{$fileDir}}) {
			my $fileDescription = $dirHsh{$fileDir}{$fileName};	
			printf OUTFILELIST ("%-".$fileDir_colLen."s %-".$fileName_colLen."s %-".$fileDescription_colLen."s\n", $fileDir, $fileName, $fileDescription);
		}
	}
	
	print OUTFILELIST "\n";
	print OUTFILELIST "\n";
	print OUTFILELIST "~" foreach (1..length "The above files were generated by running,");
	print OUTFILELIST "\n";
	print OUTFILELIST "The above files were generated by running,\n";
	print OUTFILELIST "\n";
	print OUTFILELIST "$ARGVStr\n";
	print OUTFILELIST "\n";

	close OUTFILELIST;

	return ();
}
sub printStartOrFinishMessage {
#....................................................................................................................................................#
#	subroutineCategory: general
#	dependOnSub: currentTime|534
#	appearInSub: >none
#	primaryAppearInSection: 2_defineOutDirPath|190, 5_finishingTasks|247
#	secondaryAppearInSection: >none
#	input: $StartOrFinishMessage
#	output: none
#	toCall: &printStartOrFinishMessage($StartOrFinishMessage);
#	calledInLine: 204, 251
#....................................................................................................................................................#

	my ($StartOrFinishMessage) = @_;
	
	if ($StartOrFinishMessage eq "startMessage") {
		print "\n=========================================================================\n";
		print "[".&currentTime()."] starts running ...... \n";#->534
		print "=========================================================================\n\n";

		print $tmplog_fh "\n=========================================================================\n";
		print $tmplog_fh "[".&currentTime()."] starts running ...... \n";#->534
		print $tmplog_fh "=========================================================================\n\n";

	} elsif ($StartOrFinishMessage eq "finishMessage") {
		print "\n=========================================================================\n";
		print "[".&currentTime()."] finished running .......\n";#->534
		print "=========================================================================\n\n";

		print $tmplog_fh "\n=========================================================================\n";
		print $tmplog_fh "[".&currentTime()."] finished running .......\n";#->534
		print $tmplog_fh "=========================================================================\n\n";
	}
}
sub printTssClusterBed {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $paramTag, $result_bed_dir, $tssCluster_info_hsh_ref
#	output: 
#	toCall: &printTssClusterBed($result_bed_dir, $tssCluster_info_hsh_ref, $paramTag);
#	calledInLine: 241
#....................................................................................................................................................#
	my ($result_bed_dir, $tssCluster_info_hsh_ref, $paramTag) = @_;
	
	&reportAndLogStatus("Printing merged filtered bed", 10, "\n");#->1716
	
	my $removed_bed_path = "$result_bed_dir/$paramTag.tssCluster.merged.removed.bed.gz";
	$globalReadmeHsh_ref->{$removed_bed_path}{'description'} = "Bed for merged and removed tssClusters";
	my $filtered_bed_path = "$result_bed_dir/$paramTag.tssCluster.merged.filtered.bed.gz";
	$globalReadmeHsh_ref->{$filtered_bed_path}{'description'} = "Bed for merged and filtered tssClusters";
	my $itemRgb_hsh_ref = {
		'+' => '227,26,28',
		'-' => '31,120,180',
	};
	open FILTERBED, "| sort -k1,1 -k2,2n | gzip -c >$filtered_bed_path";
	open REMOVEBED, "| sort -k1,1 -k2,2n | gzip -c >$removed_bed_path";
	foreach my $tssClusterID (keys %{$tssCluster_info_hsh_ref}) {
		my $count = $tssCluster_info_hsh_ref->{$tssClusterID}{'count'};
		my $strand = $tssCluster_info_hsh_ref->{$tssClusterID}{'strand'};
		my $chrom = $tssCluster_info_hsh_ref->{$tssClusterID}{'chrom'};
		my ($chromStart, $chromEnd) = @{$tssCluster_info_hsh_ref->{$tssClusterID}{'pos'}};
		my $blockSizes = $chromEnd - $chromStart;
		my $blockStarts = 0;
		my $thickEnd = $tssCluster_info_hsh_ref->{$tssClusterID}{'summit'};
		my $thickStart = $thickEnd - 1;
		my $blockCount = 1;
		my $itemRgb = $itemRgb_hsh_ref->{$strand};
		my $valid = $tssCluster_info_hsh_ref->{$tssClusterID}{'valid'};
		if ($valid eq 'no') {
			print REMOVEBED join "", (join "\t", ($chrom, $chromStart, $chromEnd, $tssClusterID, $count, $strand, $thickStart, $thickEnd, $itemRgb, $blockCount, $blockSizes, $blockStarts)), "\n";
		} else {
			print FILTERBED join "", (join "\t", ($chrom, $chromStart, $chromEnd, $tssClusterID, $count, $strand, $thickStart, $thickEnd, $itemRgb, $blockCount, $blockSizes, $blockStarts)), "\n";
		}
	}
	close FILTERBED;
	close REMOVEBED;

	return ();
}
sub printTssClusterLog {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 4_merge|229
#	secondaryAppearInSection: >none
#	input: $paramTag, $result_log_dir, $tssCluster_info_hsh_ref
#	output: 
#	toCall: &printTssClusterLog($result_log_dir, $tssCluster_info_hsh_ref, $paramTag);
#	calledInLine: 242
#....................................................................................................................................................#
	my ($result_log_dir, $tssCluster_info_hsh_ref, $paramTag) = @_;
	
	&reportAndLogStatus("Printing tssCluster log", 10, "\n");#->1716
	
	my $filter_log_path = "$result_log_dir/$paramTag.tssCluster.merged.filtered.log.tsv";
	my $remove_log_path = "$result_log_dir/$paramTag.tssCluster.merged.removed.log.tsv";
	open (FILTERFILE, ">", "$filter_log_path");
	open (REMOVEFILE, ">", "$remove_log_path");
	$globalReadmeHsh_ref->{$filter_log_path}{'description'} = "Information of merged and filtered tssClusters";
	$globalReadmeHsh_ref->{$remove_log_path}{'description'} = "Information of merged and filtered tssClusters";
	my @headerAry = ('tssClusterID', 'anno_region', 'valid', 'pass_lenient_polyA_cutoff', 'pass_lenient_count_cutoff', 'pass_stringent_polyA_cutoff', 'pass_stringent_count_cutoff', 'prob', 'chrom', 'strand',  'summit', 'size', 'total_summit_dnStrm_seq', 'ung_summit_dnStrm_seq', 'total_summit_dnStrm_A_frac', 'ung_summit_dnStrm_A_frac', 'max', 'count', 'ung_count', 'ung_pct', 'ung_num_pos', 'num_pos', 'ung_max', 'ung_at_total_summit', 'ung_summmit_ovrlp', 'num_cluster_merged', 'force_retain_CRE', 'num_lib', 'libID_str', 'prob_str', 'total_A_stretch_length',  'total_flank_A_frac', 'ung_A_stretch_length', 'ung_flank_A_frac', 'total_summit_flank_seq', 'ung_summit_flank_seq');
	print FILTERFILE join "", (join "\t", @headerAry), "\n";
	print REMOVEFILE join "", (join "\t", @headerAry), "\n";
	@{$globalReadmeHsh_ref->{$filter_log_path}{'headerAry'}} = @headerAry;
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'tssClusterID'} = 'ID of the tssCluster';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'chrom'} = 'chomosome';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'strand'} = 'strand';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'summit'} = 'position of the summit';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'size'} = 'size of tssCluster';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'max'} = 'count at the summit (i.e. max witin cluster)';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'count'} = 'total read count within the cluster';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_count'} = 'unencoded G read count';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_pct'} = 'unencoded G read percentage';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_num_pos'} = 'number of postion with non-zero unencoded G count';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'num_pos'} = 'number of postion with non-zero total count';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_max'} = 'number of unencoded G count at the highest (unencoded G count) postion';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_at_total_summit'} = 'number of total count at the highest (total count) postion';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_summmit_ovrlp'} = 'number of unencoded G count at the highest (total count) postion';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'prob'} = 'best probablity of all contributing tssCluster';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'libID_str'} = 'ID of libraries merged within this tssCluster';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'prob_str'} = 'comma delimited probablity of contributing tssCluster';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'num_lib'} = 'number of libraries merged within this tssCluster';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'total_summit_flank_seq'} = 'flanking sequence of the total ctss summit';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_summit_flank_seq'} = 'flanking sequence of the unencoded G ctss summit';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'total_summit_dnStrm_seq'} = 'downstream sequence of the total ctss summit';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_summit_dnStrm_seq'} = 'downstream sequence of the unencoded G ctss summit';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'total_summit_dnStrm_A_frac'} = 'fraction of downstream sequence of the total ctss summit is A';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_summit_dnStrm_A_frac'} = 'fraction of downstream sequence of the unencoded G ctss summit is A';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'anno_region'} = 'anotation region of the tssClusters belongs to';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'force_retain_CRE'} = 'force retained by intersection with CRE';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'total_A_stretch_length'} = 'maximum length of A stretch (allowing 1 mismatch) in flanking sequence of the total ctss summit';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'total_flank_A_frac'} = 'fraction of flanking sequence of the total ctss summit is A';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_A_stretch_length'} = 'maximum length of A stretch (allowing 1 mismatch) in flanking sequence of the unencoded G ctss summit';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'ung_flank_A_frac'} = 'fraction of flanking sequence of the unencoded G ctss summit is A';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'valid'} = 'valid, yes or no. yes if it passes the specific filters';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'pass_stringent_polyA_cutoff'} = 'passed the stringent polyA filter or not';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'pass_stringent_count_cutoff'} = 'passed the stringent count filter or not';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'pass_lenient_polyA_cutoff'} = 'passed the lenient polyA filter or not';
	$globalReadmeHsh_ref->{$filter_log_path}{'header'}{'pass_lenient_count_cutoff'} = 'passed the lenient count filter or not';

	@{$globalReadmeHsh_ref->{$remove_log_path}{'headerAry'}} = @headerAry;
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'tssClusterID'} = 'ID of the tssCluster';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'chrom'} = 'chomosome';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'strand'} = 'strand';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'summit'} = 'position of the summit';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'size'} = 'size of tssCluster';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'max'} = 'count at the summit (i.e. max witin cluster)';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'count'} = 'total read count within the cluster';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_count'} = 'unencoded G read count';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_pct'} = 'unencoded G read percentage';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_num_pos'} = 'number of postion with non-zero unencoded G count';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'num_pos'} = 'number of postion with non-zero total count';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_max'} = 'number of unencoded G count at the highest (unencoded G count) postion';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_at_total_summit'} = 'number of total count at the highest (total count) postion';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_summmit_ovrlp'} = 'number of unencoded G count at the highest (total count) postion';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'prob'} = 'best probablity of all contributing tssCluster';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'libID_str'} = 'ID of libraries merged within this tssCluster';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'prob_str'} = 'comma delimited probablity of contributing tssCluster';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'num_lib'} = 'number of libraries merged within this tssCluster';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'total_summit_flank_seq'} = 'flanking sequence of the total ctss summit';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_summit_flank_seq'} = 'flanking sequence of the unencoded G ctss summit';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'total_summit_dnStrm_seq'} = 'downstream sequence of the total ctss summit';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_summit_dnStrm_seq'} = 'downstream sequence of the unencoded G ctss summit';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'total_summit_dnStrm_A_frac'} = 'fraction of downstream sequence of the total ctss summit is A';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_summit_dnStrm_A_frac'} = 'fraction of downstream sequence of the unencoded G ctss summit is A';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'anno_region'} = 'anotation region of the tssClusters belongs to';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'force_retain_CRE'} = 'force retained by intersection with CRE';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'total_A_stretch_length'} = 'maximum length of A stretch (allowing 1 mismatch) in flanking sequence of the total ctss summit';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'total_flank_A_frac'} = 'fraction of flanking sequence of the total ctss summit is A';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_A_stretch_length'} = 'maximum length of A stretch (allowing 1 mismatch) in flanking sequence of the unencoded G ctss summit';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'ung_flank_A_frac'} = 'fraction of flanking sequence of the unencoded G ctss summit is A';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'valid'} = 'valid, yes or no. yes if it passes the specific filters';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'pass_stringent_polyA_cutoff'} = 'passed the stringent polyA filter or not';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'pass_stringent_count_cutoff'} = 'passed the stringent count filter or not';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'pass_lenient_polyA_cutoff'} = 'passed the lenient polyA filter or not';
	$globalReadmeHsh_ref->{$remove_log_path}{'header'}{'pass_lenient_count_cutoff'} = 'passed the lenient count filter or not';

	foreach my $tssClusterID (sort keys %{$tssCluster_info_hsh_ref}) {
		
		my $ung_num_pos = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_num_pos'};
		my $num_pos = $tssCluster_info_hsh_ref->{$tssClusterID}{'num_pos'};
		my $ung_max = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_max'};
		my $ung_at_total_summit = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_at_total_summit'};
		my $ung_summmit_ovrlp = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summmit_ovrlp'};

		my $count = $tssCluster_info_hsh_ref->{$tssClusterID}{'count'};
		my $ung_count = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_count'};
		my $ung_pct = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_pct'};
		my $max = $tssCluster_info_hsh_ref->{$tssClusterID}{'max'};
		my $strand = $tssCluster_info_hsh_ref->{$tssClusterID}{'strand'};
		my $chrom = $tssCluster_info_hsh_ref->{$tssClusterID}{'chrom'};
		my $size = $tssCluster_info_hsh_ref->{$tssClusterID}{'size'};
		my ($chromStart, $chromEnd) = @{$tssCluster_info_hsh_ref->{$tssClusterID}{'pos'}};
		my $libID_str = $tssCluster_info_hsh_ref->{$tssClusterID}{'libID_str'};
		my $prob_str = $tssCluster_info_hsh_ref->{$tssClusterID}{'prob_str'};
		my $prob = $tssCluster_info_hsh_ref->{$tssClusterID}{'prob'};
		my $num_lib = $tssCluster_info_hsh_ref->{$tssClusterID}{'num_lib'};
		my $summit = $tssCluster_info_hsh_ref->{$tssClusterID}{'summit'};
		my $num_cluster_merged = $tssCluster_info_hsh_ref->{$tssClusterID}{'num_cluster_merged'};
		my $total_summit_flank_seq = $tssCluster_info_hsh_ref->{$tssClusterID}{'total_summit_flank_seq'};
		my $ung_summit_flank_seq = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summit_flank_seq'};
		my $total_summit_dnStrm_seq = $tssCluster_info_hsh_ref->{$tssClusterID}{'total_summit_dnStrm_seq'};
		my $ung_summit_dnStrm_seq = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summit_dnStrm_seq'};
		my $total_summit_dnStrm_A_frac = $tssCluster_info_hsh_ref->{$tssClusterID}{'total_summit_dnStrm_A_frac'};
		my $ung_summit_dnStrm_A_frac = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_summit_dnStrm_A_frac'};
		my $anno_region = $tssCluster_info_hsh_ref->{$tssClusterID}{'anno_region'};
		my $total_A_stretch_length = $tssCluster_info_hsh_ref->{$tssClusterID}{'total_A_stretch_length'};
		my $total_flank_A_frac = $tssCluster_info_hsh_ref->{$tssClusterID}{'total_flank_A_frac'};
		my $ung_A_stretch_length = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_A_stretch_length'};
		my $ung_flank_A_frac = $tssCluster_info_hsh_ref->{$tssClusterID}{'ung_flank_A_frac'};
		my $force_retain_CRE = $tssCluster_info_hsh_ref->{$tssClusterID}{'force_retain_CRE'};

		my $valid = $tssCluster_info_hsh_ref->{$tssClusterID}{'valid'};
		my $pass_stringent_polyA_cutoff = $tssCluster_info_hsh_ref->{$tssClusterID}{'pass_stringent_polyA_cutoff'};
		my $pass_stringent_count_cutoff = $tssCluster_info_hsh_ref->{$tssClusterID}{'pass_stringent_count_cutoff'};
		my $pass_lenient_polyA_cutoff = $tssCluster_info_hsh_ref->{$tssClusterID}{'pass_lenient_polyA_cutoff'};
		my $pass_lenient_count_cutoff = $tssCluster_info_hsh_ref->{$tssClusterID}{'pass_lenient_count_cutoff'};
		
		my @output_ary = ($tssClusterID, $anno_region, $valid, $pass_lenient_polyA_cutoff, $pass_lenient_count_cutoff, $pass_stringent_polyA_cutoff, $pass_stringent_count_cutoff, $prob, $chrom, $strand,  $summit, $size, $total_summit_dnStrm_seq, $ung_summit_dnStrm_seq, $total_summit_dnStrm_A_frac, $ung_summit_dnStrm_A_frac, $max, $count, $ung_count, $ung_pct, $ung_num_pos, $num_pos, $ung_max, $ung_at_total_summit, $ung_summmit_ovrlp, $num_cluster_merged, $force_retain_CRE, $num_lib, $libID_str, $prob_str, $total_A_stretch_length,  $total_flank_A_frac, $ung_A_stretch_length, $ung_flank_A_frac, $total_summit_flank_seq, $ung_summit_flank_seq);
		
		if ($valid eq 'no') {
			print REMOVEFILE join "", (join "\t", @output_ary), "\n";
		} else {
			print FILTERFILE join "", (join "\t", @output_ary), "\n";
		}
	}
	
	close FILTERFILE;
	close REMOVEFILE;

	return ();
}
sub readLibCutoff {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 3_generate_chunk|210
#	secondaryAppearInSection: >none
#	input: $default_cutoff_hsh_ref, $lib_info_hsh_ref, $lib_region_filter_criteria_path, $paramTag, $result_log_dir
#	output: 
#	toCall: &readLibCutoff($lib_info_hsh_ref, $default_cutoff_hsh_ref, $lib_region_filter_criteria_path, $result_log_dir, $paramTag);
#	calledInLine: 224
#....................................................................................................................................................#
	my ($lib_info_hsh_ref, $default_cutoff_hsh_ref, $lib_region_filter_criteria_path, $result_log_dir, $paramTag) = @_;

	foreach my $libID (keys %{$lib_info_hsh_ref}) {
		foreach my $r (@{$default_cutoff_hsh_ref->{'r'}}) {#---[2023/05/12 14:33] foreach region
			foreach my $param (keys %{$default_cutoff_hsh_ref->{'param'}}) {#---[2023/05/12 14:33] foreach param
				$lib_info_hsh_ref->{$libID}{'cutoff'}{$r}{$param} = $default_cutoff_hsh_ref->{'param'}{$param}; 
			}
		}
	}
	
	&reportAndLogStatus("reading custom filter criteria", 10, "\n");#->1716
	open INCUTOFF, "<", $lib_region_filter_criteria_path;
	while (<INCUTOFF>) {
		#HCAJ0001.HCAJ0001-m7-1	r[intron:ss,exon:ss]|p[0.75];r[end5:ss]|p[0.25]
		#HCAJ0001.HCAJ0001-m4-2	r[intron:ss,exon:ss]|t[5]|m[3]|u[3]|p[0.90]
		#HCAJ0001.HCAJ0001-c4-2	r[intron:ss,exon:ss]|t[5]|m[3]|u[3]|p[0.75]
		#HCAJ0001.HCAJ0001-c2-2	r[intron:ss,exon:ss]|t[5]|m[3]|u[3]|p[0.50]
		chomp;
		my ($libID, $filter_string) = split /\t/;
		foreach my $group_filter_string (split /\;/, $filter_string) {
			my $custom_cutoff_hsh_ref = {};

			foreach my $indiv_filter_string (split /\|/, $group_filter_string) {
				if ($indiv_filter_string =~ m/(\w)\[(.+)\]/) {
					my $param = $1;
					my $value = $2;

					if ($param eq 'r') {
					
						foreach my $r (split /\,/, $value) {
							if (not grep { $_ eq $r } @{$default_cutoff_hsh_ref->{'r'}}) {#---[2023/05/12 15:16] make sure the region is in the default cutoff hsh
								die "region $r in filter_string $filter_string of $libID is not valid\n";
							}
						
							push @{$custom_cutoff_hsh_ref->{'r'}}, $r;
						}
						
					} else {
						if (not exists $default_cutoff_hsh_ref->{'param'}{$param}) {
							die "param $param in filter_string $filter_string of $libID is not valid\n";
						}
						$custom_cutoff_hsh_ref->{'param'}{$param} = $value;
					}

				} else {
					die "filter_string $filter_string of $libID is not formatted properly\n";
				}
			}

			if (not exists $custom_cutoff_hsh_ref->{'r'}) { #---[2023/05/12 15:11] apply cutoff to all regions if not specified
				$custom_cutoff_hsh_ref->{'r'} = $default_cutoff_hsh_ref->{'r'}; 
			}
			
			foreach my $r (@{$custom_cutoff_hsh_ref->{'r'}}) {#---[2023/05/12 14:33] foreach region
				foreach my $param (keys %{$custom_cutoff_hsh_ref->{'param'}}) {#---[2023/05/12 14:33] foreach param
					my $value = $custom_cutoff_hsh_ref->{'param'}{$param};
					$lib_info_hsh_ref->{$libID}{'cutoff'}{$r}{$param} = $value;
					&reportAndLogStatus("setting libID $libID region $r param $param to $value", 10, "\n");#->1716
				}
			}
		}
	}
	close INCUTOFF;

	my $out_log_path = "$result_log_dir/$paramTag.lib.region.cutoff.log.tsv";
	open OUTCUTOFFLOG, ">", $out_log_path;
	my @region_ary = sort @{$default_cutoff_hsh_ref->{'r'}};
	my @param_ary = ();

	foreach my $param (sort keys %{$default_cutoff_hsh_ref->{'param'}}) {#---[2023/05/12 14:33] foreach param
		push @param_ary, $param;
	}
	my @headerAry = ('libID', 'r', @param_ary);
	$globalReadmeHsh_ref->{$out_log_path}{'description'} = "Cutoffs used to filter tssClusters in different region in individual libraries";
	@{$globalReadmeHsh_ref->{$out_log_path}{'headerAry'}} = @headerAry;
	$globalReadmeHsh_ref->{$out_log_path}{'header'}{'libID'} = 'ID of the tssCluster';
	$globalReadmeHsh_ref->{$out_log_path}{'header'}{'r'} = 'region category, as end5:as, end5:ss, exon:as, exon:ss, intergenic:ns, intron:as, intron:ss';
	$globalReadmeHsh_ref->{$out_log_path}{'header'}{'p'} = 'minimum logistic probality [default 0.5]';
	$globalReadmeHsh_ref->{$out_log_path}{'header'}{'t'} = 'minimum total umi/read count [default 3]';
	$globalReadmeHsh_ref->{$out_log_path}{'header'}{'m'} = 'minimum max (summit) umi/read count [default 0]';
	$globalReadmeHsh_ref->{$out_log_path}{'header'}{'u'} = 'minimum unencoded G umi/read count [default 2]';

	print OUTCUTOFFLOG join "", (join "\t", @headerAry), "\n";
	foreach my $libID (sort keys %{$lib_info_hsh_ref}) {
		foreach my $r (@region_ary) {
			my @output_ary = ($libID, $r);
			foreach my $param (@param_ary) {
				my $value = $lib_info_hsh_ref->{$libID}{'cutoff'}{$r}{$param};
				push @output_ary, $value;
			}
			print OUTCUTOFFLOG join "", (join "\t", (@output_ary)), "\n";
		}
	}
	close OUTCUTOFFLOG;

	return ();
}
sub readLibInfo {
#....................................................................................................................................................#
#	subroutineCategory: unassigned
#	dependOnSub: reportAndLogStatus|1716
#	appearInSub: >none
#	primaryAppearInSection: 3_generate_chunk|210
#	secondaryAppearInSection: >none
#	input: $lib_list_path
#	output: $lib_info_hsh_ref
#	toCall: my ($lib_info_hsh_ref) = &readLibInfo($lib_list_path);
#	calledInLine: 223
#....................................................................................................................................................#
	my ($lib_list_path) = @_;
	
	my $lib_info_hsh_ref = {};
	open LIBINFO, "<", $lib_list_path;
	while (<LIBINFO>) {
		chomp;
		my ($libID, $tssCluster_filter_log_path, $tssCluster_all_bed_path) = split /\t/;
		die "tssCluster_filter_log_path of libID $libID does not exists\n" if not -s $tssCluster_filter_log_path;
		die "tssCluster_all_bed_path of libID $libID does not exists\n" if not -s $tssCluster_all_bed_path;
		$lib_info_hsh_ref->{$libID}{'tssCluster_filter_log_path'} = $tssCluster_filter_log_path;
		$lib_info_hsh_ref->{$libID}{'tssCluster_all_bed_path'} = $tssCluster_all_bed_path;
		&reportAndLogStatus("libID $libID tssCluster_filter_log_path is stored", 10, "\n");#->1716
	}
	
	return ($lib_info_hsh_ref);
}
sub readParameters {
#....................................................................................................................................................#
#	subroutineCategory: general
#	dependOnSub: >none
#	appearInSub: >none
#	primaryAppearInSection: 0_startingTasks|162
#	secondaryAppearInSection: >none
#	input: none
#	output: $A_stretch_length_length, $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $force_retain_CRE_bed, $genome, $lib_list_path, $lib_region_filter_criteria_path, $max_flank_A_frac, $max_summit_dnStrm_A_frac, $merge_dist, $min_count, $min_max, $min_num_pos, $min_ung_at_total_summit, $min_ung_count, $min_ung_max, $min_ung_num_pos, $outDir, $outputPrefix, $overwrite, $summit_dnStrm_size, $summit_flank_size
#	toCall: my ($lib_list_path, $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $lib_region_filter_criteria_path, $merge_dist, $min_ung_count, $min_count, $min_ung_num_pos, $min_num_pos, $min_ung_max, $min_max, $min_ung_at_total_summit, $genome, $force_retain_CRE_bed, $summit_flank_size, $summit_dnStrm_size, $max_summit_dnStrm_A_frac, $max_flank_A_frac, $A_stretch_length_length, $outputPrefix, $outDir, $overwrite) = &readParameters();
#	calledInLine: 165
#....................................................................................................................................................#
	
	my ($lib_list_path, $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $lib_region_filter_criteria_path, $merge_dist, $min_ung_count, $min_count, $min_ung_num_pos, $min_num_pos, $min_ung_max, $min_max, $min_ung_at_total_summit, $genome, $force_retain_CRE_bed, $summit_flank_size, $summit_dnStrm_size, $max_summit_dnStrm_A_frac, $max_flank_A_frac, $A_stretch_length_length, $outputPrefix, $outDir, $overwrite);
	
	$overwrite = 'no';
	$merge_dist = 25;
	$min_ung_count = 8;
	$min_count = 10;
	$min_ung_num_pos = 4;
	$min_num_pos = 5;
	$min_ung_max = 4;
	$min_max = 5;
	$min_ung_at_total_summit = 0;
	$force_retain_CRE_bed = undef;
	$summit_flank_size = 25; #---[2023/05/15 12:46] for logging the sequence 
	$summit_dnStrm_size = 10; #---[2023/05/15 12:46] for calculate of fraction
	$max_summit_dnStrm_A_frac = 0.8; #---[2023/05/15 12:48] any tssCluster with total or ung summit downstream sequence (length by summit_dnStrm_size) has greater of equal max_summit_dnStrm_A_frac will be removed.
	$max_flank_A_frac = 0.75; #---[2023/05/15 12:48] any tssCluster with total or ung summit downstream sequence (length by summit_dnStrm_size) has greater of equal max_summit_dnStrm_A_frac will be removed.
	$A_stretch_length_length = 20; #---[2023/05/15 12:48] any tssCluster with total or ung summit downstream sequence (length by summit_dnStrm_size) has greater of equal max_summit_dnStrm_A_frac will be removed.

	GetOptions 	(
		"lib_list_path=s"												=>	\$lib_list_path,
		"aggregated_collapse_ctss_bed_path=s"					=>	\$aggregated_collapse_ctss_bed_path,
		"aggregated_unencoded_G_collapse_ctss_bed_path=s"	=>	\$aggregated_unencoded_G_collapse_ctss_bed_path,
		"lib_region_filter_criteria_path:s"						=>	\$lib_region_filter_criteria_path,
		"merge_dist:i"													=>	\$merge_dist,
		"min_ung_count:i"												=>	\$min_ung_count,
		"min_count:i"													=>	\$min_count,
		"min_ung_num_pos:i"											=>	\$min_ung_num_pos,
		"min_num_pos:i"												=>	\$min_num_pos,
		"min_ung_max:i"												=>	\$min_ung_max,
		"min_max:i"														=>	\$min_max,
		"min_ung_at_total_summit:i"								=>	\$min_ung_at_total_summit,
		"summit_flank_size:i"										=>	\$summit_flank_size,
		"summit_dnStrm_size:i"										=>	\$summit_dnStrm_size,
		"max_summit_dnStrm_A_frac:f"								=>	\$max_summit_dnStrm_A_frac,
		"max_flank_A_frac:f"											=>	\$max_flank_A_frac,
		"A_stretch_length_length:i"									=>	\$min_ung_at_total_summit,
		"force_retain_CRE_bed:s"									=>	\$force_retain_CRE_bed,
		"genome=s"														=>	\$genome,
		"outputPrefix=s"												=>	\$outputPrefix,
		"outDir=s"														=>	\$outDir,
		"overwrite:s"													=>	\$overwrite,
		'help'															=>	sub { HelpMessage(0) },
	) or HelpMessage(1);

	HelpMessage(1) unless $lib_list_path;
	
	#---check file
	my $file_check_hsh_ref = {
		'lib_list_path' 											=>	$lib_list_path,
		'aggregated_collapse_ctss_bed_path'					=>	$aggregated_collapse_ctss_bed_path,
		'aggregated_unencoded_G_collapse_ctss_bed_path'	=>	$aggregated_unencoded_G_collapse_ctss_bed_path,
	};
	
	if (defined $force_retain_CRE_bed) {
		$file_check_hsh_ref->{'force_retain_CRE_bed'} = $force_retain_CRE_bed;
	}
	
	foreach my $option_name (keys %{$file_check_hsh_ref}) {
		my $file_path = $file_check_hsh_ref->{$option_name};
		die "Quitting: File $option_name does not exists at $file_path" if not -s $file_path;
	}
	
	chop $outDir if ($outDir =~ m/\/$/); #---remove the last slash
	system "mkdir -p -m 755 $outDir/";

	return($lib_list_path, $aggregated_collapse_ctss_bed_path, $aggregated_unencoded_G_collapse_ctss_bed_path, $lib_region_filter_criteria_path, $merge_dist, $min_ung_count, $min_count, $min_ung_num_pos, $min_num_pos, $min_ung_max, $min_max, $min_ung_at_total_summit, $genome, $force_retain_CRE_bed, $summit_flank_size, $summit_dnStrm_size, $max_summit_dnStrm_A_frac, $max_flank_A_frac, $A_stretch_length_length, $outputPrefix, $outDir, $overwrite);

}
sub reportAndLogStatus {
#....................................................................................................................................................#
#	subroutineCategory: log
#	dependOnSub: currentTime|534
#	appearInSub: assignTssClusterToAnnnotationRegions|285, checkAllExecutable|393, filterLibTssCluster|552, filterMergedTssCluster|626, forceRetainCRE|740, getClusterSequence|814, getTssClusterCount|951, mergeTssClusters|1061, printTssClusterBed|1295, printTssClusterLog|1344, readLibCutoff|1498, readLibInfo|1607
#	primaryAppearInSection: 3_generate_chunk|210
#	secondaryAppearInSection: 2_defineOutDirPath|190, 3_generate_chunk|210, 4_merge|229
#	input: $lineEnd, $message, $numTrailingSpace
#	output: 
#	toCall: &reportAndLogStatus($message, $numTrailingSpace, $lineEnd);
#	calledInLine: 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 312, 333, 358, 367, 380, 416, 421, 430, 439, 448, 457, 466, 475, 484, 604, 607, 639, 735, 757, 783, 860, 889, 964, 983, 987, 1008, 1089, 1140, 1308, 1357, 1519, 1566, 1629
#....................................................................................................................................................#
	my ($message, $numTrailingSpace, $lineEnd) = @_;

	my $trailingSpaces = '';
	$trailingSpaces .= " " for (1..$numTrailingSpace);
	
	print "[".&currentTime()."] ".$message.$trailingSpaces.$lineEnd;#->534
	print $tmplog_fh "[".&currentTime()."] ".$message.$lineEnd if $lineEnd ne "\r";#->534
	
	return ();
}
sub timeStamp {
#....................................................................................................................................................#
#	subroutineCategory: time, general
#	dependOnSub: >none
#	appearInSub: >none
#	primaryAppearInSection: >none
#	secondaryAppearInSection: >none
#	input: none
#	output: $curntTimeStamp
#	toCall: my ($curntTimeStamp) = &timeStamp();
#	calledInLine: 150
#....................................................................................................................................................#
	
	my ($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst)=localtime(time);
	my $curntTimeStamp = sprintf "%04d.%02d.%02d.%02d.%02d.%02d", $year+1900,$mon+1,$mday,$hour,$min,$sec;	

	return ($curntTimeStamp);
}

exit;


















































